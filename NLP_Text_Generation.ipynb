{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Text-Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUqbvUoyvl9NXVvIVuzRHC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-alamdari/NLP-Text-Generation/blob/main/NLP_Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RI_jcozpCSkG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path):\n",
        "  with open(path) as f:\n",
        "    my_str = f.read()\n",
        "  return my_str"
      ],
      "metadata": {
        "id": "tXbO-eV8DTlE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mr-alamdari/NLP-Text-Generation/main/moby_dick_four_chapters.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APaNWzndLmWz",
        "outputId": "0d3533d6-58b7-4e6c-a825-6b45caf8e433"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-01 16:45:38--  https://raw.githubusercontent.com/mr-alamdari/NLP-Text-Generation/main/moby_dick_four_chapters.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62685 (61K) [text/plain]\n",
            "Saving to: ‘moby_dick_four_chapters.txt’\n",
            "\n",
            "\r          moby_dick   0%[                    ]       0  --.-KB/s               \rmoby_dick_four_chap 100%[===================>]  61.22K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-05-01 16:45:38 (5.27 MB/s) - ‘moby_dick_four_chapters.txt’ saved [62685/62685]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobydic = read_file('moby_dick_four_chapters.txt')"
      ],
      "metadata": {
        "id": "cAHX5_zpMHcR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])"
      ],
      "metadata": {
        "id": "86o5KMUtMMU9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.max_length = 1198623"
      ],
      "metadata": {
        "id": "haHP59oAMaxi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seperate_punc = lambda doc: [token.text.lower() for token in nlp(doc) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n']"
      ],
      "metadata": {
        "id": "qJeXlTZqMfQ5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = seperate_punc(mobydic)"
      ],
      "metadata": {
        "id": "fd8pOF7tNJ2i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr6zfeu4OR1F",
        "outputId": "a61944bd-a768-4be2-eaa6-dee8875e7799"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['call',\n",
              " 'me',\n",
              " 'ishmael',\n",
              " 'some',\n",
              " 'years',\n",
              " 'ago',\n",
              " 'never',\n",
              " 'mind',\n",
              " 'how',\n",
              " 'long',\n",
              " 'precisely',\n",
              " 'having',\n",
              " 'little',\n",
              " 'or',\n",
              " 'no',\n",
              " 'money',\n",
              " 'in',\n",
              " 'my',\n",
              " 'purse',\n",
              " 'and']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVAMB0NxOXbP",
        "outputId": "29a861ab-4b34-4b40-f761-c5bae03159f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11338"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = 25 + 1 # 25 training words , then one target word\n",
        "\n",
        "text_sequences = [tokens[i-train_len: i] for i in range(train_len, len(tokens))]"
      ],
      "metadata": {
        "id": "XL8YjU2COZSH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Y0v8PDafPPqj",
        "outputId": "1969470b-a803-4368-c7dc-8569bcab555e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "jUXGwHtdPS9v",
        "outputId": "4c136fc7-9776-489f-8452-5886983533fb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "t-y62vtIPVAu",
        "outputId": "16a08828-3d69-45b1-98ea-23077dace648"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RtJ-Ma-CPWQm",
        "outputId": "d7cb28ec-9198-446c-8803-f49346545017"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ZILcMszCPYGW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()"
      ],
      "metadata": {
        "id": "KzA8jCL1P1ND"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(text_sequences)"
      ],
      "metadata": {
        "id": "Ob0Vvjb6P7_c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "metadata": {
        "id": "0VkIxCAKQCOt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)"
      ],
      "metadata": {
        "id": "E5wpsIKCSDtO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V2xV_5VQKpD",
        "outputId": "c9faf097-ea25-486b-9c53-ed5af4ceb320"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 956   14  263   51  261  408   87  219  129  111  954  260   50   43\n",
            "   38  315    7   23  546    3  150  259    6 2712   14   24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNDJsDy6QPtg",
        "outputId": "f7624b49-ccdd-4df2-f344-e824d2560b85"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  14  263   51  261  408   87  219  129  111  954  260   50   43   38\n",
            "  315    7   23  546    3  150  259    6 2712   14   24  957]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdvYQNAJQZfy",
        "outputId": "97cb1783-2fa9-4db7-fee5-b5a44b930919"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 263   51  261  408   87  219  129  111  954  260   50   43   38  315\n",
            "    7   23  546    3  150  259    6 2712   14   24  957    5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcp9dZBlQhF_",
        "outputId": "b3666409-8ae5-4111-c040-87e3367051fa"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  51  261  408   87  219  129  111  954  260   50   43   38  315    7\n",
            "   23  546    3  150  259    6 2712   14   24  957    5   60]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sequences[0]:\n",
        "  print(i, tokenizer.index_word[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn7ThErxQiE3",
        "outputId": "259ae870-440b-495c-b3e3-ee651807b92a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "956 call\n",
            "14 me\n",
            "263 ishmael\n",
            "51 some\n",
            "261 years\n",
            "408 ago\n",
            "87 never\n",
            "219 mind\n",
            "129 how\n",
            "111 long\n",
            "954 precisely\n",
            "260 having\n",
            "50 little\n",
            "43 or\n",
            "38 no\n",
            "315 money\n",
            "7 in\n",
            "23 my\n",
            "546 purse\n",
            "3 and\n",
            "150 nothing\n",
            "259 particular\n",
            "6 to\n",
            "2712 interest\n",
            "14 me\n",
            "24 on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, count in enumerate(sorted(tokenizer.word_counts.items(), key=lambda x: -x[1])):\n",
        "  if i == 20:\n",
        "    break\n",
        "  print(i, count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9h2BpwSQkJP",
        "outputId": "e30e3aa8-fcd9-4579-9989-47800ff277ca"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ('the', 15540)\n",
            "1 ('a', 10377)\n",
            "2 ('and', 9646)\n",
            "3 ('of', 8287)\n",
            "4 ('i', 7150)\n",
            "5 ('to', 6497)\n",
            "6 ('in', 5647)\n",
            "7 ('it', 4238)\n",
            "8 ('that', 3770)\n",
            "9 ('he', 3247)\n",
            "10 ('his', 3139)\n",
            "11 ('was', 2886)\n",
            "12 ('but', 2652)\n",
            "13 ('me', 2471)\n",
            "14 ('with', 2392)\n",
            "15 ('as', 2366)\n",
            "16 ('at', 2184)\n",
            "17 ('this', 2158)\n",
            "18 ('you', 2158)\n",
            "19 ('is', 1950)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(tokenizer.word_counts)"
      ],
      "metadata": {
        "id": "evu-ezjARN85"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcNKQxuoR8vi",
        "outputId": "5ab86390-7603-4c2f-d863-ad870abf4d68"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sequences[:, :-1]"
      ],
      "metadata": {
        "id": "xfuppMV4hD6r"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = sequences[:, -1]"
      ],
      "metadata": {
        "id": "4teFrSvshGrr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size+1)"
      ],
      "metadata": {
        "id": "eckFK4icR9sz"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = x.shape[1]"
      ],
      "metadata": {
        "id": "xwmmMyiMhM57"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocab_size, seq_len):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(vocab_size, seq_len, input_length=seq_len))\n",
        "  model.add(tf.keras.layers.LSTM(seq_len, return_sequences=True))\n",
        "  model.add(tf.keras.layers.LSTM(seq_len))\n",
        "  model.add(tf.keras.layers.Dense(seq_len, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(vocab_size, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer = 'adam',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "aFkT3a2mhYwu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size+1, seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMsPblA2ijXA",
        "outputId": "805cc063-2034-4436-ac1a-fee2ee60f2fc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 25, 25)            67950     \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 25, 25)            5100      \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 25)                5100      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 25)                650       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2718)              70668     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 149,468\n",
            "Trainable params: 149,468\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import dump, load"
      ],
      "metadata": {
        "id": "vHmiENS8in9p"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=32, epochs=20, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5awVfQddjAuo",
        "outputId": "46f0ac88-07a4-4827-e82f-5472fae3d7e1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "354/354 - 9s - loss: 5.9622 - accuracy: 0.0586 - 9s/epoch - 26ms/step\n",
            "Epoch 2/20\n",
            "354/354 - 9s - loss: 5.8368 - accuracy: 0.0643 - 9s/epoch - 26ms/step\n",
            "Epoch 3/20\n",
            "354/354 - 9s - loss: 5.7486 - accuracy: 0.0657 - 9s/epoch - 26ms/step\n",
            "Epoch 4/20\n",
            "354/354 - 9s - loss: 5.6548 - accuracy: 0.0675 - 9s/epoch - 26ms/step\n",
            "Epoch 5/20\n",
            "354/354 - 9s - loss: 5.5733 - accuracy: 0.0690 - 9s/epoch - 26ms/step\n",
            "Epoch 6/20\n",
            "354/354 - 9s - loss: 5.5074 - accuracy: 0.0738 - 9s/epoch - 25ms/step\n",
            "Epoch 7/20\n",
            "354/354 - 9s - loss: 5.4458 - accuracy: 0.0758 - 9s/epoch - 26ms/step\n",
            "Epoch 8/20\n",
            "354/354 - 9s - loss: 5.3802 - accuracy: 0.0785 - 9s/epoch - 26ms/step\n",
            "Epoch 9/20\n",
            "354/354 - 9s - loss: 5.3125 - accuracy: 0.0823 - 9s/epoch - 26ms/step\n",
            "Epoch 10/20\n",
            "354/354 - 9s - loss: 5.2486 - accuracy: 0.0828 - 9s/epoch - 26ms/step\n",
            "Epoch 11/20\n",
            "354/354 - 9s - loss: 5.1911 - accuracy: 0.0852 - 9s/epoch - 26ms/step\n",
            "Epoch 12/20\n",
            "354/354 - 9s - loss: 5.1332 - accuracy: 0.0887 - 9s/epoch - 27ms/step\n",
            "Epoch 13/20\n",
            "354/354 - 9s - loss: 5.0783 - accuracy: 0.0909 - 9s/epoch - 26ms/step\n",
            "Epoch 14/20\n",
            "354/354 - 9s - loss: 5.0273 - accuracy: 0.0950 - 9s/epoch - 26ms/step\n",
            "Epoch 15/20\n",
            "354/354 - 9s - loss: 4.9738 - accuracy: 0.0972 - 9s/epoch - 26ms/step\n",
            "Epoch 16/20\n",
            "354/354 - 9s - loss: 4.9186 - accuracy: 0.1009 - 9s/epoch - 26ms/step\n",
            "Epoch 17/20\n",
            "354/354 - 9s - loss: 4.8642 - accuracy: 0.1048 - 9s/epoch - 25ms/step\n",
            "Epoch 18/20\n",
            "354/354 - 9s - loss: 4.8150 - accuracy: 0.1064 - 9s/epoch - 25ms/step\n",
            "Epoch 19/20\n",
            "354/354 - 9s - loss: 4.7650 - accuracy: 0.1088 - 9s/epoch - 25ms/step\n",
            "Epoch 20/20\n",
            "354/354 - 9s - loss: 4.7074 - accuracy: 0.1133 - 9s/epoch - 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a5e0b2950>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mobydic_model.h5')"
      ],
      "metadata": {
        "id": "rO-bgPG-jI1g"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dump(tokenizer, open('simpleTokenizer', 'wb'))"
      ],
      "metadata": {
        "id": "SnM6PofKjVhv"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "  output_text = []\n",
        "  input_text = seed_text\n",
        "  for i in range(num_gen_words):\n",
        "    encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "    pad_encoded = tf.keras.preprocessing.sequence.pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "    pred_word = model.predict(pad_encoded, verbose=0)[0]\n",
        "    pred_word_ind = np.argmax(pred_word)\n",
        "    pred_word = tokenizer.index_word[pred_word_ind]\n",
        "    input_text += ' '+pred_word\n",
        "    output_text.append(pred_word)\n",
        "  return ' '.join(output_text)"
      ],
      "metadata": {
        "id": "fsevAqi8jbwT"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_gen_words = 20\n",
        "n = np.random.randint(0, len(text_sequences))\n",
        "generate_text(model, tokenizer, seq_len, ' '.join(text_sequences[n]), num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "tu_qGhvHlU5t",
        "outputId": "87ef9b71-10f1-45e4-fc67-94515ef5645e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'the man and be not be was was be be and be and be not be not be not be'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=32, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0xdCeX3nx_w",
        "outputId": "87e973eb-8391-41ed-8e6b-fb04a4e5546e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "354/354 - 9s - loss: 4.6543 - accuracy: 0.1146 - 9s/epoch - 26ms/step\n",
            "Epoch 2/100\n",
            "354/354 - 9s - loss: 4.5950 - accuracy: 0.1180 - 9s/epoch - 25ms/step\n",
            "Epoch 3/100\n",
            "354/354 - 9s - loss: 4.5381 - accuracy: 0.1201 - 9s/epoch - 25ms/step\n",
            "Epoch 4/100\n",
            "354/354 - 9s - loss: 4.4843 - accuracy: 0.1255 - 9s/epoch - 26ms/step\n",
            "Epoch 5/100\n",
            "354/354 - 9s - loss: 4.4360 - accuracy: 0.1284 - 9s/epoch - 25ms/step\n",
            "Epoch 6/100\n",
            "354/354 - 9s - loss: 4.3852 - accuracy: 0.1302 - 9s/epoch - 25ms/step\n",
            "Epoch 7/100\n",
            "354/354 - 9s - loss: 4.3371 - accuracy: 0.1339 - 9s/epoch - 25ms/step\n",
            "Epoch 8/100\n",
            "354/354 - 9s - loss: 4.2858 - accuracy: 0.1386 - 9s/epoch - 25ms/step\n",
            "Epoch 9/100\n",
            "354/354 - 9s - loss: 4.2336 - accuracy: 0.1408 - 9s/epoch - 25ms/step\n",
            "Epoch 10/100\n",
            "354/354 - 9s - loss: 4.1891 - accuracy: 0.1475 - 9s/epoch - 25ms/step\n",
            "Epoch 11/100\n",
            "354/354 - 9s - loss: 4.1395 - accuracy: 0.1479 - 9s/epoch - 25ms/step\n",
            "Epoch 12/100\n",
            "354/354 - 9s - loss: 4.0992 - accuracy: 0.1514 - 9s/epoch - 25ms/step\n",
            "Epoch 13/100\n",
            "354/354 - 9s - loss: 4.0545 - accuracy: 0.1535 - 9s/epoch - 25ms/step\n",
            "Epoch 14/100\n",
            "354/354 - 9s - loss: 4.0141 - accuracy: 0.1594 - 9s/epoch - 25ms/step\n",
            "Epoch 15/100\n",
            "354/354 - 9s - loss: 3.9756 - accuracy: 0.1620 - 9s/epoch - 25ms/step\n",
            "Epoch 16/100\n",
            "354/354 - 9s - loss: 3.9265 - accuracy: 0.1650 - 9s/epoch - 26ms/step\n",
            "Epoch 17/100\n",
            "354/354 - 9s - loss: 3.8896 - accuracy: 0.1696 - 9s/epoch - 25ms/step\n",
            "Epoch 18/100\n",
            "354/354 - 9s - loss: 3.8399 - accuracy: 0.1770 - 9s/epoch - 25ms/step\n",
            "Epoch 19/100\n",
            "354/354 - 9s - loss: 3.8111 - accuracy: 0.1782 - 9s/epoch - 25ms/step\n",
            "Epoch 20/100\n",
            "354/354 - 9s - loss: 3.7753 - accuracy: 0.1835 - 9s/epoch - 25ms/step\n",
            "Epoch 21/100\n",
            "354/354 - 9s - loss: 3.7329 - accuracy: 0.1879 - 9s/epoch - 25ms/step\n",
            "Epoch 22/100\n",
            "354/354 - 9s - loss: 3.7003 - accuracy: 0.1915 - 9s/epoch - 25ms/step\n",
            "Epoch 23/100\n",
            "354/354 - 9s - loss: 3.6667 - accuracy: 0.1985 - 9s/epoch - 25ms/step\n",
            "Epoch 24/100\n",
            "354/354 - 9s - loss: 3.6243 - accuracy: 0.2029 - 9s/epoch - 25ms/step\n",
            "Epoch 25/100\n",
            "354/354 - 9s - loss: 3.5953 - accuracy: 0.2082 - 9s/epoch - 25ms/step\n",
            "Epoch 26/100\n",
            "354/354 - 9s - loss: 3.5534 - accuracy: 0.2148 - 9s/epoch - 25ms/step\n",
            "Epoch 27/100\n",
            "354/354 - 9s - loss: 3.5307 - accuracy: 0.2175 - 9s/epoch - 25ms/step\n",
            "Epoch 28/100\n",
            "354/354 - 9s - loss: 3.5022 - accuracy: 0.2223 - 9s/epoch - 25ms/step\n",
            "Epoch 29/100\n",
            "354/354 - 9s - loss: 3.4683 - accuracy: 0.2283 - 9s/epoch - 25ms/step\n",
            "Epoch 30/100\n",
            "354/354 - 9s - loss: 3.4412 - accuracy: 0.2341 - 9s/epoch - 25ms/step\n",
            "Epoch 31/100\n",
            "354/354 - 9s - loss: 3.4101 - accuracy: 0.2397 - 9s/epoch - 25ms/step\n",
            "Epoch 32/100\n",
            "354/354 - 9s - loss: 3.3750 - accuracy: 0.2413 - 9s/epoch - 25ms/step\n",
            "Epoch 33/100\n",
            "354/354 - 9s - loss: 3.3501 - accuracy: 0.2481 - 9s/epoch - 25ms/step\n",
            "Epoch 34/100\n",
            "354/354 - 9s - loss: 3.3227 - accuracy: 0.2490 - 9s/epoch - 25ms/step\n",
            "Epoch 35/100\n",
            "354/354 - 9s - loss: 3.2981 - accuracy: 0.2547 - 9s/epoch - 25ms/step\n",
            "Epoch 36/100\n",
            "354/354 - 9s - loss: 3.2810 - accuracy: 0.2618 - 9s/epoch - 25ms/step\n",
            "Epoch 37/100\n",
            "354/354 - 9s - loss: 3.2565 - accuracy: 0.2604 - 9s/epoch - 25ms/step\n",
            "Epoch 38/100\n",
            "354/354 - 9s - loss: 3.2217 - accuracy: 0.2687 - 9s/epoch - 25ms/step\n",
            "Epoch 39/100\n",
            "354/354 - 9s - loss: 3.1926 - accuracy: 0.2752 - 9s/epoch - 25ms/step\n",
            "Epoch 40/100\n",
            "354/354 - 9s - loss: 3.1688 - accuracy: 0.2811 - 9s/epoch - 25ms/step\n",
            "Epoch 41/100\n",
            "354/354 - 9s - loss: 3.1376 - accuracy: 0.2829 - 9s/epoch - 25ms/step\n",
            "Epoch 42/100\n",
            "354/354 - 9s - loss: 3.1121 - accuracy: 0.2849 - 9s/epoch - 25ms/step\n",
            "Epoch 43/100\n",
            "354/354 - 9s - loss: 3.0934 - accuracy: 0.2936 - 9s/epoch - 25ms/step\n",
            "Epoch 44/100\n",
            "354/354 - 9s - loss: 3.0858 - accuracy: 0.2917 - 9s/epoch - 25ms/step\n",
            "Epoch 45/100\n",
            "354/354 - 9s - loss: 3.0510 - accuracy: 0.2993 - 9s/epoch - 25ms/step\n",
            "Epoch 46/100\n",
            "354/354 - 9s - loss: 3.0179 - accuracy: 0.3031 - 9s/epoch - 25ms/step\n",
            "Epoch 47/100\n",
            "354/354 - 9s - loss: 3.0004 - accuracy: 0.3092 - 9s/epoch - 25ms/step\n",
            "Epoch 48/100\n",
            "354/354 - 9s - loss: 2.9727 - accuracy: 0.3142 - 9s/epoch - 25ms/step\n",
            "Epoch 49/100\n",
            "354/354 - 9s - loss: 2.9491 - accuracy: 0.3179 - 9s/epoch - 25ms/step\n",
            "Epoch 50/100\n",
            "354/354 - 9s - loss: 2.9262 - accuracy: 0.3236 - 9s/epoch - 25ms/step\n",
            "Epoch 51/100\n",
            "354/354 - 9s - loss: 2.9064 - accuracy: 0.3289 - 9s/epoch - 26ms/step\n",
            "Epoch 52/100\n",
            "354/354 - 9s - loss: 2.8900 - accuracy: 0.3266 - 9s/epoch - 25ms/step\n",
            "Epoch 53/100\n",
            "354/354 - 9s - loss: 2.8587 - accuracy: 0.3323 - 9s/epoch - 25ms/step\n",
            "Epoch 54/100\n",
            "354/354 - 9s - loss: 2.8471 - accuracy: 0.3360 - 9s/epoch - 25ms/step\n",
            "Epoch 55/100\n",
            "354/354 - 9s - loss: 2.8220 - accuracy: 0.3430 - 9s/epoch - 25ms/step\n",
            "Epoch 56/100\n",
            "354/354 - 9s - loss: 2.7992 - accuracy: 0.3504 - 9s/epoch - 25ms/step\n",
            "Epoch 57/100\n",
            "354/354 - 9s - loss: 2.7708 - accuracy: 0.3514 - 9s/epoch - 25ms/step\n",
            "Epoch 58/100\n",
            "354/354 - 9s - loss: 2.7598 - accuracy: 0.3528 - 9s/epoch - 25ms/step\n",
            "Epoch 59/100\n",
            "354/354 - 9s - loss: 2.7347 - accuracy: 0.3593 - 9s/epoch - 25ms/step\n",
            "Epoch 60/100\n",
            "354/354 - 9s - loss: 2.7066 - accuracy: 0.3672 - 9s/epoch - 25ms/step\n",
            "Epoch 61/100\n",
            "354/354 - 9s - loss: 2.6991 - accuracy: 0.3624 - 9s/epoch - 25ms/step\n",
            "Epoch 62/100\n",
            "354/354 - 9s - loss: 2.6790 - accuracy: 0.3701 - 9s/epoch - 25ms/step\n",
            "Epoch 63/100\n",
            "354/354 - 9s - loss: 2.6569 - accuracy: 0.3776 - 9s/epoch - 25ms/step\n",
            "Epoch 64/100\n",
            "354/354 - 9s - loss: 2.6270 - accuracy: 0.3792 - 9s/epoch - 25ms/step\n",
            "Epoch 65/100\n",
            "354/354 - 9s - loss: 2.6028 - accuracy: 0.3828 - 9s/epoch - 25ms/step\n",
            "Epoch 66/100\n",
            "354/354 - 9s - loss: 2.5984 - accuracy: 0.3827 - 9s/epoch - 25ms/step\n",
            "Epoch 67/100\n",
            "354/354 - 9s - loss: 2.5781 - accuracy: 0.3871 - 9s/epoch - 25ms/step\n",
            "Epoch 68/100\n",
            "354/354 - 9s - loss: 2.5470 - accuracy: 0.3958 - 9s/epoch - 25ms/step\n",
            "Epoch 69/100\n",
            "354/354 - 9s - loss: 2.5271 - accuracy: 0.4036 - 9s/epoch - 25ms/step\n",
            "Epoch 70/100\n",
            "354/354 - 9s - loss: 2.5199 - accuracy: 0.3991 - 9s/epoch - 25ms/step\n",
            "Epoch 71/100\n",
            "354/354 - 9s - loss: 2.5134 - accuracy: 0.4045 - 9s/epoch - 25ms/step\n",
            "Epoch 72/100\n",
            "354/354 - 9s - loss: 2.4984 - accuracy: 0.4029 - 9s/epoch - 24ms/step\n",
            "Epoch 73/100\n",
            "354/354 - 9s - loss: 2.4759 - accuracy: 0.4107 - 9s/epoch - 24ms/step\n",
            "Epoch 74/100\n",
            "354/354 - 9s - loss: 2.4474 - accuracy: 0.4113 - 9s/epoch - 24ms/step\n",
            "Epoch 75/100\n",
            "354/354 - 9s - loss: 2.4153 - accuracy: 0.4236 - 9s/epoch - 24ms/step\n",
            "Epoch 76/100\n",
            "354/354 - 9s - loss: 2.3981 - accuracy: 0.4286 - 9s/epoch - 24ms/step\n",
            "Epoch 77/100\n",
            "354/354 - 9s - loss: 2.3807 - accuracy: 0.4313 - 9s/epoch - 24ms/step\n",
            "Epoch 78/100\n",
            "354/354 - 9s - loss: 2.3858 - accuracy: 0.4337 - 9s/epoch - 25ms/step\n",
            "Epoch 79/100\n",
            "354/354 - 9s - loss: 2.3491 - accuracy: 0.4368 - 9s/epoch - 25ms/step\n",
            "Epoch 80/100\n",
            "354/354 - 9s - loss: 2.3294 - accuracy: 0.4411 - 9s/epoch - 24ms/step\n",
            "Epoch 81/100\n",
            "354/354 - 9s - loss: 2.3305 - accuracy: 0.4446 - 9s/epoch - 25ms/step\n",
            "Epoch 82/100\n",
            "354/354 - 9s - loss: 2.3026 - accuracy: 0.4483 - 9s/epoch - 25ms/step\n",
            "Epoch 83/100\n",
            "354/354 - 9s - loss: 2.2900 - accuracy: 0.4492 - 9s/epoch - 25ms/step\n",
            "Epoch 84/100\n",
            "354/354 - 9s - loss: 2.2719 - accuracy: 0.4505 - 9s/epoch - 25ms/step\n",
            "Epoch 85/100\n",
            "354/354 - 9s - loss: 2.2502 - accuracy: 0.4613 - 9s/epoch - 25ms/step\n",
            "Epoch 86/100\n",
            "354/354 - 9s - loss: 2.2302 - accuracy: 0.4646 - 9s/epoch - 24ms/step\n",
            "Epoch 87/100\n",
            "354/354 - 9s - loss: 2.2206 - accuracy: 0.4648 - 9s/epoch - 24ms/step\n",
            "Epoch 88/100\n",
            "354/354 - 9s - loss: 2.1964 - accuracy: 0.4655 - 9s/epoch - 24ms/step\n",
            "Epoch 89/100\n",
            "354/354 - 9s - loss: 2.1926 - accuracy: 0.4687 - 9s/epoch - 25ms/step\n",
            "Epoch 90/100\n",
            "354/354 - 9s - loss: 2.1777 - accuracy: 0.4707 - 9s/epoch - 24ms/step\n",
            "Epoch 91/100\n",
            "354/354 - 9s - loss: 2.1488 - accuracy: 0.4794 - 9s/epoch - 25ms/step\n",
            "Epoch 92/100\n",
            "354/354 - 9s - loss: 2.1413 - accuracy: 0.4796 - 9s/epoch - 24ms/step\n",
            "Epoch 93/100\n",
            "354/354 - 9s - loss: 2.1253 - accuracy: 0.4811 - 9s/epoch - 24ms/step\n",
            "Epoch 94/100\n",
            "354/354 - 9s - loss: 2.1036 - accuracy: 0.4871 - 9s/epoch - 24ms/step\n",
            "Epoch 95/100\n",
            "354/354 - 9s - loss: 2.0933 - accuracy: 0.4915 - 9s/epoch - 24ms/step\n",
            "Epoch 96/100\n",
            "354/354 - 9s - loss: 2.0861 - accuracy: 0.4928 - 9s/epoch - 24ms/step\n",
            "Epoch 97/100\n",
            "354/354 - 9s - loss: 2.0670 - accuracy: 0.4986 - 9s/epoch - 24ms/step\n",
            "Epoch 98/100\n",
            "354/354 - 9s - loss: 2.0690 - accuracy: 0.4981 - 9s/epoch - 24ms/step\n",
            "Epoch 99/100\n",
            "354/354 - 9s - loss: 2.0441 - accuracy: 0.5024 - 9s/epoch - 24ms/step\n",
            "Epoch 100/100\n",
            "354/354 - 9s - loss: 2.0283 - accuracy: 0.5037 - 9s/epoch - 24ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3a5e054550>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_gen_words = 40\n",
        "n = np.random.randint(0, len(text_sequences))\n",
        "generate_text(model, tokenizer, seq_len, ' '.join(text_sequences[n]), num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "MvXucMEOnzoT",
        "outputId": "63f9ebab-fd9b-4333-e66a-0facd21622a6"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"n't do n't be not be not almost be been four the original of if it is a southerner and said the landlord and presently to be two off i say not the urbane plaster man i abandon the business\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kM_W-VOfsFQ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}