{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Text-Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMj26bIcLM7zVrx93poG3KU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-alamdari/NLP-Text-Generation/blob/main/NLP_Text_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RI_jcozpCSkG"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from pickle import dump, load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path):\n",
        "  with open(path) as f:\n",
        "    my_str = f.read()\n",
        "  return my_str"
      ],
      "metadata": {
        "id": "tXbO-eV8DTlE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mr-alamdari/NLP-Text-Generation/main/moby_dick_four_chapters.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APaNWzndLmWz",
        "outputId": "3555ea8d-e1a1-4a32-b1ed-f78587474e2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-03 11:42:41--  https://raw.githubusercontent.com/mr-alamdari/NLP-Text-Generation/main/moby_dick_four_chapters.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 62685 (61K) [text/plain]\n",
            "Saving to: ‘moby_dick_four_chapters.txt’\n",
            "\n",
            "\r          moby_dick   0%[                    ]       0  --.-KB/s               \rmoby_dick_four_chap 100%[===================>]  61.22K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-05-03 11:42:41 (66.8 MB/s) - ‘moby_dick_four_chapters.txt’ saved [62685/62685]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mobydic = read_file('moby_dick_four_chapters.txt')"
      ],
      "metadata": {
        "id": "cAHX5_zpMHcR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'tagger', 'ner'])"
      ],
      "metadata": {
        "id": "86o5KMUtMMU9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.max_length = 1198623"
      ],
      "metadata": {
        "id": "haHP59oAMaxi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seperate_punc = lambda doc: [token.text.lower() for token in nlp(doc) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n']"
      ],
      "metadata": {
        "id": "qJeXlTZqMfQ5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = seperate_punc(mobydic)"
      ],
      "metadata": {
        "id": "fd8pOF7tNJ2i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[20:40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xr6zfeu4OR1F",
        "outputId": "adc24ab4-6b52-4b90-a428-d17d51d67f8f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nothing',\n",
              " 'particular',\n",
              " 'to',\n",
              " 'interest',\n",
              " 'me',\n",
              " 'on',\n",
              " 'shore',\n",
              " 'i',\n",
              " 'thought',\n",
              " 'i',\n",
              " 'would',\n",
              " 'sail',\n",
              " 'about',\n",
              " 'a',\n",
              " 'little',\n",
              " 'and',\n",
              " 'see',\n",
              " 'the',\n",
              " 'watery',\n",
              " 'part']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVAMB0NxOXbP",
        "outputId": "1e3f29cd-427f-4c7f-d7b4-68335d6de82a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11338"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = 25 + 1 # 25 training words , then one target word\n",
        "\n",
        "text_sequences = [tokens[i-train_len: i] for i in range(train_len, len(tokens))]"
      ],
      "metadata": {
        "id": "XL8YjU2COZSH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Y0v8PDafPPqj",
        "outputId": "3a9b6b7d-e04f-4bec-8712-eb10e0cb5516"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "jUXGwHtdPS9v",
        "outputId": "f568397e-48b0-4cba-889c-0522228c9445"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "t-y62vtIPVAu",
        "outputId": "abc0645a-b14e-468b-fc89-a8525e8737a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(text_sequences[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RtJ-Ma-CPWQm",
        "outputId": "c35e5c72-fa7f-46cb-d0a5-7ec82d8ca109"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i thought'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ZILcMszCPYGW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()"
      ],
      "metadata": {
        "id": "KzA8jCL1P1ND"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(text_sequences)"
      ],
      "metadata": {
        "id": "Ob0Vvjb6P7_c"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer.texts_to_sequences(text_sequences)"
      ],
      "metadata": {
        "id": "0VkIxCAKQCOt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = np.array(sequences)"
      ],
      "metadata": {
        "id": "E5wpsIKCSDtO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3V2xV_5VQKpD",
        "outputId": "0142534c-cafe-4254-d387-695a42a9b177"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 956   14  263   51  261  408   87  219  129  111  954  260   50   43\n",
            "   38  315    7   23  546    3  150  259    6 2712   14   24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNDJsDy6QPtg",
        "outputId": "38f8bddc-5200-4b53-8657-b44d598470b2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  14  263   51  261  408   87  219  129  111  954  260   50   43   38\n",
            "  315    7   23  546    3  150  259    6 2712   14   24  957]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TdvYQNAJQZfy",
        "outputId": "9cab0c35-ab4a-4d3e-8989-e1431b1a1370"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 263   51  261  408   87  219  129  111  954  260   50   43   38  315\n",
            "    7   23  546    3  150  259    6 2712   14   24  957    5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sequences[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gcp9dZBlQhF_",
        "outputId": "af928aed-a73d-42da-8978-0c48a9ec54b8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  51  261  408   87  219  129  111  954  260   50   43   38  315    7\n",
            "   23  546    3  150  259    6 2712   14   24  957    5   60]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in sequences[0]:\n",
        "  print(i, tokenizer.index_word[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn7ThErxQiE3",
        "outputId": "4d8b098d-27b9-4b54-cc8d-a527e62a69e2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "956 call\n",
            "14 me\n",
            "263 ishmael\n",
            "51 some\n",
            "261 years\n",
            "408 ago\n",
            "87 never\n",
            "219 mind\n",
            "129 how\n",
            "111 long\n",
            "954 precisely\n",
            "260 having\n",
            "50 little\n",
            "43 or\n",
            "38 no\n",
            "315 money\n",
            "7 in\n",
            "23 my\n",
            "546 purse\n",
            "3 and\n",
            "150 nothing\n",
            "259 particular\n",
            "6 to\n",
            "2712 interest\n",
            "14 me\n",
            "24 on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, count in enumerate(sorted(tokenizer.word_counts.items(), key=lambda x: -x[1])):\n",
        "  if i == 30:\n",
        "    break\n",
        "  print(i, count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9h2BpwSQkJP",
        "outputId": "f83c4dde-6d8d-42ab-e13b-da27bd4eda0b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ('the', 15540)\n",
            "1 ('a', 10377)\n",
            "2 ('and', 9646)\n",
            "3 ('of', 8287)\n",
            "4 ('i', 7150)\n",
            "5 ('to', 6497)\n",
            "6 ('in', 5647)\n",
            "7 ('it', 4238)\n",
            "8 ('that', 3770)\n",
            "9 ('he', 3247)\n",
            "10 ('his', 3139)\n",
            "11 ('was', 2886)\n",
            "12 ('but', 2652)\n",
            "13 ('me', 2471)\n",
            "14 ('with', 2392)\n",
            "15 ('as', 2366)\n",
            "16 ('at', 2184)\n",
            "17 ('this', 2158)\n",
            "18 ('you', 2158)\n",
            "19 ('is', 1950)\n",
            "20 ('all', 1872)\n",
            "21 ('for', 1820)\n",
            "22 ('my', 1786)\n",
            "23 ('on', 1716)\n",
            "24 ('be', 1716)\n",
            "25 (\"'s\", 1691)\n",
            "26 ('not', 1534)\n",
            "27 ('from', 1508)\n",
            "28 ('there', 1456)\n",
            "29 ('one', 1300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(tokenizer.word_counts)"
      ],
      "metadata": {
        "id": "evu-ezjARN85"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcNKQxuoR8vi",
        "outputId": "ecd3d332-cb97-4f68-c3ab-9400b6dfc92d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2717"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = sequences[:, :-1]"
      ],
      "metadata": {
        "id": "xfuppMV4hD6r"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = sequences[:, -1]"
      ],
      "metadata": {
        "id": "4teFrSvshGrr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size+1)"
      ],
      "metadata": {
        "id": "eckFK4icR9sz"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len = x.shape[1]"
      ],
      "metadata": {
        "id": "xwmmMyiMhM57"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(vocab_size, seq_len):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(vocab_size, seq_len, input_length=seq_len))\n",
        "  model.add(tf.keras.layers.LSTM(seq_len, return_sequences=True))\n",
        "  model.add(tf.keras.layers.LSTM(seq_len))\n",
        "  model.add(tf.keras.layers.Dense(seq_len, activation='relu'))\n",
        "  model.add(tf.keras.layers.Dense(vocab_size, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer = 'adam',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "  return model"
      ],
      "metadata": {
        "id": "aFkT3a2mhYwu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(vocab_size+1, seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMsPblA2ijXA",
        "outputId": "51f86369-a119-4d36-e5d7-266c9f9263e4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 25, 25)            67950     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 25, 25)            5100      \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 25)                5100      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 25)                650       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2718)              70668     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 149,468\n",
            "Trainable params: 149,468\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=32, epochs=200, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5awVfQddjAuo",
        "outputId": "25305f77-9502-4523-929e-14f6d1c72ed1"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "354/354 - 8s - loss: 6.1576 - accuracy: 0.0517 - 8s/epoch - 23ms/step\n",
            "Epoch 2/200\n",
            "354/354 - 8s - loss: 6.0735 - accuracy: 0.0530 - 8s/epoch - 23ms/step\n",
            "Epoch 3/200\n",
            "354/354 - 8s - loss: 5.9708 - accuracy: 0.0541 - 8s/epoch - 23ms/step\n",
            "Epoch 4/200\n",
            "354/354 - 8s - loss: 5.8935 - accuracy: 0.0595 - 8s/epoch - 23ms/step\n",
            "Epoch 5/200\n",
            "354/354 - 8s - loss: 5.8123 - accuracy: 0.0656 - 8s/epoch - 23ms/step\n",
            "Epoch 6/200\n",
            "354/354 - 8s - loss: 5.7355 - accuracy: 0.0663 - 8s/epoch - 24ms/step\n",
            "Epoch 7/200\n",
            "354/354 - 8s - loss: 5.6799 - accuracy: 0.0681 - 8s/epoch - 23ms/step\n",
            "Epoch 8/200\n",
            "354/354 - 8s - loss: 5.6341 - accuracy: 0.0667 - 8s/epoch - 23ms/step\n",
            "Epoch 9/200\n",
            "354/354 - 8s - loss: 5.5914 - accuracy: 0.0674 - 8s/epoch - 23ms/step\n",
            "Epoch 10/200\n",
            "354/354 - 8s - loss: 5.5460 - accuracy: 0.0682 - 8s/epoch - 23ms/step\n",
            "Epoch 11/200\n",
            "354/354 - 8s - loss: 5.5051 - accuracy: 0.0703 - 8s/epoch - 23ms/step\n",
            "Epoch 12/200\n",
            "354/354 - 8s - loss: 5.4649 - accuracy: 0.0714 - 8s/epoch - 23ms/step\n",
            "Epoch 13/200\n",
            "354/354 - 8s - loss: 5.4254 - accuracy: 0.0743 - 8s/epoch - 23ms/step\n",
            "Epoch 14/200\n",
            "354/354 - 8s - loss: 5.3903 - accuracy: 0.0750 - 8s/epoch - 23ms/step\n",
            "Epoch 15/200\n",
            "354/354 - 8s - loss: 5.3522 - accuracy: 0.0749 - 8s/epoch - 23ms/step\n",
            "Epoch 16/200\n",
            "354/354 - 8s - loss: 5.3174 - accuracy: 0.0773 - 8s/epoch - 23ms/step\n",
            "Epoch 17/200\n",
            "354/354 - 8s - loss: 5.2803 - accuracy: 0.0785 - 8s/epoch - 23ms/step\n",
            "Epoch 18/200\n",
            "354/354 - 8s - loss: 5.2402 - accuracy: 0.0833 - 8s/epoch - 23ms/step\n",
            "Epoch 19/200\n",
            "354/354 - 8s - loss: 5.2019 - accuracy: 0.0841 - 8s/epoch - 23ms/step\n",
            "Epoch 20/200\n",
            "354/354 - 8s - loss: 5.1577 - accuracy: 0.0881 - 8s/epoch - 23ms/step\n",
            "Epoch 21/200\n",
            "354/354 - 8s - loss: 5.1125 - accuracy: 0.0935 - 8s/epoch - 23ms/step\n",
            "Epoch 22/200\n",
            "354/354 - 8s - loss: 5.0642 - accuracy: 0.0945 - 8s/epoch - 23ms/step\n",
            "Epoch 23/200\n",
            "354/354 - 8s - loss: 5.0202 - accuracy: 0.1002 - 8s/epoch - 23ms/step\n",
            "Epoch 24/200\n",
            "354/354 - 8s - loss: 4.9737 - accuracy: 0.1014 - 8s/epoch - 23ms/step\n",
            "Epoch 25/200\n",
            "354/354 - 8s - loss: 4.9308 - accuracy: 0.1017 - 8s/epoch - 23ms/step\n",
            "Epoch 26/200\n",
            "354/354 - 8s - loss: 4.8864 - accuracy: 0.1040 - 8s/epoch - 23ms/step\n",
            "Epoch 27/200\n",
            "354/354 - 8s - loss: 4.8446 - accuracy: 0.1122 - 8s/epoch - 23ms/step\n",
            "Epoch 28/200\n",
            "354/354 - 8s - loss: 4.8008 - accuracy: 0.1140 - 8s/epoch - 23ms/step\n",
            "Epoch 29/200\n",
            "354/354 - 8s - loss: 4.7596 - accuracy: 0.1155 - 8s/epoch - 23ms/step\n",
            "Epoch 30/200\n",
            "354/354 - 8s - loss: 4.7137 - accuracy: 0.1165 - 8s/epoch - 23ms/step\n",
            "Epoch 31/200\n",
            "354/354 - 8s - loss: 4.6690 - accuracy: 0.1208 - 8s/epoch - 23ms/step\n",
            "Epoch 32/200\n",
            "354/354 - 8s - loss: 4.6256 - accuracy: 0.1251 - 8s/epoch - 23ms/step\n",
            "Epoch 33/200\n",
            "354/354 - 8s - loss: 4.5770 - accuracy: 0.1295 - 8s/epoch - 23ms/step\n",
            "Epoch 34/200\n",
            "354/354 - 8s - loss: 4.5289 - accuracy: 0.1308 - 8s/epoch - 23ms/step\n",
            "Epoch 35/200\n",
            "354/354 - 8s - loss: 4.4860 - accuracy: 0.1323 - 8s/epoch - 23ms/step\n",
            "Epoch 36/200\n",
            "354/354 - 8s - loss: 4.4382 - accuracy: 0.1331 - 8s/epoch - 23ms/step\n",
            "Epoch 37/200\n",
            "354/354 - 8s - loss: 4.3977 - accuracy: 0.1363 - 8s/epoch - 23ms/step\n",
            "Epoch 38/200\n",
            "354/354 - 8s - loss: 4.3472 - accuracy: 0.1384 - 8s/epoch - 23ms/step\n",
            "Epoch 39/200\n",
            "354/354 - 8s - loss: 4.3026 - accuracy: 0.1460 - 8s/epoch - 23ms/step\n",
            "Epoch 40/200\n",
            "354/354 - 8s - loss: 4.2579 - accuracy: 0.1495 - 8s/epoch - 23ms/step\n",
            "Epoch 41/200\n",
            "354/354 - 8s - loss: 4.2018 - accuracy: 0.1509 - 8s/epoch - 23ms/step\n",
            "Epoch 42/200\n",
            "354/354 - 8s - loss: 4.1581 - accuracy: 0.1540 - 8s/epoch - 23ms/step\n",
            "Epoch 43/200\n",
            "354/354 - 8s - loss: 4.0983 - accuracy: 0.1583 - 8s/epoch - 23ms/step\n",
            "Epoch 44/200\n",
            "354/354 - 8s - loss: 4.0385 - accuracy: 0.1649 - 8s/epoch - 23ms/step\n",
            "Epoch 45/200\n",
            "354/354 - 8s - loss: 3.9885 - accuracy: 0.1688 - 8s/epoch - 23ms/step\n",
            "Epoch 46/200\n",
            "354/354 - 8s - loss: 3.9353 - accuracy: 0.1726 - 8s/epoch - 23ms/step\n",
            "Epoch 47/200\n",
            "354/354 - 8s - loss: 3.8888 - accuracy: 0.1816 - 8s/epoch - 23ms/step\n",
            "Epoch 48/200\n",
            "354/354 - 8s - loss: 3.8425 - accuracy: 0.1842 - 8s/epoch - 23ms/step\n",
            "Epoch 49/200\n",
            "354/354 - 8s - loss: 3.7928 - accuracy: 0.1909 - 8s/epoch - 23ms/step\n",
            "Epoch 50/200\n",
            "354/354 - 8s - loss: 3.7427 - accuracy: 0.1962 - 8s/epoch - 23ms/step\n",
            "Epoch 51/200\n",
            "354/354 - 8s - loss: 3.7019 - accuracy: 0.2054 - 8s/epoch - 23ms/step\n",
            "Epoch 52/200\n",
            "354/354 - 8s - loss: 3.6681 - accuracy: 0.2103 - 8s/epoch - 23ms/step\n",
            "Epoch 53/200\n",
            "354/354 - 8s - loss: 3.6238 - accuracy: 0.2155 - 8s/epoch - 23ms/step\n",
            "Epoch 54/200\n",
            "354/354 - 8s - loss: 3.5820 - accuracy: 0.2229 - 8s/epoch - 23ms/step\n",
            "Epoch 55/200\n",
            "354/354 - 8s - loss: 3.5447 - accuracy: 0.2320 - 8s/epoch - 23ms/step\n",
            "Epoch 56/200\n",
            "354/354 - 8s - loss: 3.5095 - accuracy: 0.2344 - 8s/epoch - 23ms/step\n",
            "Epoch 57/200\n",
            "354/354 - 8s - loss: 3.4766 - accuracy: 0.2376 - 8s/epoch - 23ms/step\n",
            "Epoch 58/200\n",
            "354/354 - 8s - loss: 3.4427 - accuracy: 0.2429 - 8s/epoch - 23ms/step\n",
            "Epoch 59/200\n",
            "354/354 - 8s - loss: 3.4063 - accuracy: 0.2519 - 8s/epoch - 23ms/step\n",
            "Epoch 60/200\n",
            "354/354 - 8s - loss: 3.3732 - accuracy: 0.2559 - 8s/epoch - 23ms/step\n",
            "Epoch 61/200\n",
            "354/354 - 8s - loss: 3.3500 - accuracy: 0.2592 - 8s/epoch - 23ms/step\n",
            "Epoch 62/200\n",
            "354/354 - 8s - loss: 3.3247 - accuracy: 0.2666 - 8s/epoch - 23ms/step\n",
            "Epoch 63/200\n",
            "354/354 - 8s - loss: 3.2810 - accuracy: 0.2711 - 8s/epoch - 23ms/step\n",
            "Epoch 64/200\n",
            "354/354 - 8s - loss: 3.2528 - accuracy: 0.2769 - 8s/epoch - 23ms/step\n",
            "Epoch 65/200\n",
            "354/354 - 8s - loss: 3.2251 - accuracy: 0.2827 - 8s/epoch - 23ms/step\n",
            "Epoch 66/200\n",
            "354/354 - 8s - loss: 3.1937 - accuracy: 0.2866 - 8s/epoch - 23ms/step\n",
            "Epoch 67/200\n",
            "354/354 - 8s - loss: 3.1822 - accuracy: 0.2883 - 8s/epoch - 23ms/step\n",
            "Epoch 68/200\n",
            "354/354 - 8s - loss: 3.1573 - accuracy: 0.2887 - 8s/epoch - 23ms/step\n",
            "Epoch 69/200\n",
            "354/354 - 8s - loss: 3.1138 - accuracy: 0.3007 - 8s/epoch - 23ms/step\n",
            "Epoch 70/200\n",
            "354/354 - 8s - loss: 3.0842 - accuracy: 0.3060 - 8s/epoch - 23ms/step\n",
            "Epoch 71/200\n",
            "354/354 - 8s - loss: 3.0741 - accuracy: 0.3094 - 8s/epoch - 23ms/step\n",
            "Epoch 72/200\n",
            "354/354 - 8s - loss: 3.0464 - accuracy: 0.3161 - 8s/epoch - 23ms/step\n",
            "Epoch 73/200\n",
            "354/354 - 8s - loss: 3.0165 - accuracy: 0.3156 - 8s/epoch - 23ms/step\n",
            "Epoch 74/200\n",
            "354/354 - 8s - loss: 2.9929 - accuracy: 0.3236 - 8s/epoch - 23ms/step\n",
            "Epoch 75/200\n",
            "354/354 - 8s - loss: 2.9680 - accuracy: 0.3251 - 8s/epoch - 23ms/step\n",
            "Epoch 76/200\n",
            "354/354 - 8s - loss: 2.9456 - accuracy: 0.3284 - 8s/epoch - 23ms/step\n",
            "Epoch 77/200\n",
            "354/354 - 8s - loss: 2.9287 - accuracy: 0.3327 - 8s/epoch - 23ms/step\n",
            "Epoch 78/200\n",
            "354/354 - 8s - loss: 2.9059 - accuracy: 0.3375 - 8s/epoch - 23ms/step\n",
            "Epoch 79/200\n",
            "354/354 - 8s - loss: 2.8886 - accuracy: 0.3390 - 8s/epoch - 23ms/step\n",
            "Epoch 80/200\n",
            "354/354 - 8s - loss: 2.8553 - accuracy: 0.3453 - 8s/epoch - 23ms/step\n",
            "Epoch 81/200\n",
            "354/354 - 8s - loss: 2.8373 - accuracy: 0.3507 - 8s/epoch - 23ms/step\n",
            "Epoch 82/200\n",
            "354/354 - 8s - loss: 2.8103 - accuracy: 0.3556 - 8s/epoch - 23ms/step\n",
            "Epoch 83/200\n",
            "354/354 - 8s - loss: 2.7918 - accuracy: 0.3563 - 8s/epoch - 23ms/step\n",
            "Epoch 84/200\n",
            "354/354 - 8s - loss: 2.7668 - accuracy: 0.3631 - 8s/epoch - 23ms/step\n",
            "Epoch 85/200\n",
            "354/354 - 8s - loss: 2.7549 - accuracy: 0.3621 - 8s/epoch - 23ms/step\n",
            "Epoch 86/200\n",
            "354/354 - 8s - loss: 2.7336 - accuracy: 0.3671 - 8s/epoch - 23ms/step\n",
            "Epoch 87/200\n",
            "354/354 - 8s - loss: 2.7262 - accuracy: 0.3705 - 8s/epoch - 23ms/step\n",
            "Epoch 88/200\n",
            "354/354 - 8s - loss: 2.6900 - accuracy: 0.3791 - 8s/epoch - 23ms/step\n",
            "Epoch 89/200\n",
            "354/354 - 8s - loss: 2.6706 - accuracy: 0.3825 - 8s/epoch - 23ms/step\n",
            "Epoch 90/200\n",
            "354/354 - 8s - loss: 2.6486 - accuracy: 0.3887 - 8s/epoch - 23ms/step\n",
            "Epoch 91/200\n",
            "354/354 - 8s - loss: 2.6351 - accuracy: 0.3893 - 8s/epoch - 23ms/step\n",
            "Epoch 92/200\n",
            "354/354 - 8s - loss: 2.6218 - accuracy: 0.3920 - 8s/epoch - 23ms/step\n",
            "Epoch 93/200\n",
            "354/354 - 8s - loss: 2.5967 - accuracy: 0.3977 - 8s/epoch - 23ms/step\n",
            "Epoch 94/200\n",
            "354/354 - 8s - loss: 2.5825 - accuracy: 0.3989 - 8s/epoch - 23ms/step\n",
            "Epoch 95/200\n",
            "354/354 - 8s - loss: 2.5535 - accuracy: 0.4026 - 8s/epoch - 23ms/step\n",
            "Epoch 96/200\n",
            "354/354 - 8s - loss: 2.5438 - accuracy: 0.4059 - 8s/epoch - 23ms/step\n",
            "Epoch 97/200\n",
            "354/354 - 8s - loss: 2.5175 - accuracy: 0.4128 - 8s/epoch - 23ms/step\n",
            "Epoch 98/200\n",
            "354/354 - 8s - loss: 2.5008 - accuracy: 0.4142 - 8s/epoch - 23ms/step\n",
            "Epoch 99/200\n",
            "354/354 - 8s - loss: 2.4774 - accuracy: 0.4243 - 8s/epoch - 23ms/step\n",
            "Epoch 100/200\n",
            "354/354 - 8s - loss: 2.4688 - accuracy: 0.4197 - 8s/epoch - 23ms/step\n",
            "Epoch 101/200\n",
            "354/354 - 8s - loss: 2.4603 - accuracy: 0.4273 - 8s/epoch - 23ms/step\n",
            "Epoch 102/200\n",
            "354/354 - 8s - loss: 2.4476 - accuracy: 0.4242 - 8s/epoch - 23ms/step\n",
            "Epoch 103/200\n",
            "354/354 - 8s - loss: 2.4185 - accuracy: 0.4345 - 8s/epoch - 23ms/step\n",
            "Epoch 104/200\n",
            "354/354 - 8s - loss: 2.3933 - accuracy: 0.4366 - 8s/epoch - 23ms/step\n",
            "Epoch 105/200\n",
            "354/354 - 8s - loss: 2.3820 - accuracy: 0.4384 - 8s/epoch - 23ms/step\n",
            "Epoch 106/200\n",
            "354/354 - 8s - loss: 2.3766 - accuracy: 0.4379 - 8s/epoch - 23ms/step\n",
            "Epoch 107/200\n",
            "354/354 - 8s - loss: 2.3591 - accuracy: 0.4444 - 8s/epoch - 23ms/step\n",
            "Epoch 108/200\n",
            "354/354 - 8s - loss: 2.3227 - accuracy: 0.4489 - 8s/epoch - 23ms/step\n",
            "Epoch 109/200\n",
            "354/354 - 8s - loss: 2.3078 - accuracy: 0.4519 - 8s/epoch - 23ms/step\n",
            "Epoch 110/200\n",
            "354/354 - 8s - loss: 2.3000 - accuracy: 0.4550 - 8s/epoch - 23ms/step\n",
            "Epoch 111/200\n",
            "354/354 - 8s - loss: 2.2972 - accuracy: 0.4539 - 8s/epoch - 23ms/step\n",
            "Epoch 112/200\n",
            "354/354 - 8s - loss: 2.2855 - accuracy: 0.4582 - 8s/epoch - 23ms/step\n",
            "Epoch 113/200\n",
            "354/354 - 8s - loss: 2.2642 - accuracy: 0.4614 - 8s/epoch - 23ms/step\n",
            "Epoch 114/200\n",
            "354/354 - 8s - loss: 2.2276 - accuracy: 0.4702 - 8s/epoch - 23ms/step\n",
            "Epoch 115/200\n",
            "354/354 - 8s - loss: 2.2318 - accuracy: 0.4662 - 8s/epoch - 23ms/step\n",
            "Epoch 116/200\n",
            "354/354 - 8s - loss: 2.2090 - accuracy: 0.4745 - 8s/epoch - 23ms/step\n",
            "Epoch 117/200\n",
            "354/354 - 8s - loss: 2.1926 - accuracy: 0.4739 - 8s/epoch - 23ms/step\n",
            "Epoch 118/200\n",
            "354/354 - 8s - loss: 2.1875 - accuracy: 0.4792 - 8s/epoch - 23ms/step\n",
            "Epoch 119/200\n",
            "354/354 - 8s - loss: 2.1702 - accuracy: 0.4819 - 8s/epoch - 23ms/step\n",
            "Epoch 120/200\n",
            "354/354 - 8s - loss: 2.1572 - accuracy: 0.4844 - 8s/epoch - 23ms/step\n",
            "Epoch 121/200\n",
            "354/354 - 8s - loss: 2.1433 - accuracy: 0.4882 - 8s/epoch - 23ms/step\n",
            "Epoch 122/200\n",
            "354/354 - 8s - loss: 2.1302 - accuracy: 0.4912 - 8s/epoch - 23ms/step\n",
            "Epoch 123/200\n",
            "354/354 - 8s - loss: 2.1025 - accuracy: 0.4891 - 8s/epoch - 23ms/step\n",
            "Epoch 124/200\n",
            "354/354 - 8s - loss: 2.0887 - accuracy: 0.5022 - 8s/epoch - 23ms/step\n",
            "Epoch 125/200\n",
            "354/354 - 8s - loss: 2.0799 - accuracy: 0.5001 - 8s/epoch - 23ms/step\n",
            "Epoch 126/200\n",
            "354/354 - 8s - loss: 2.0633 - accuracy: 0.5064 - 8s/epoch - 23ms/step\n",
            "Epoch 127/200\n",
            "354/354 - 8s - loss: 2.0609 - accuracy: 0.5081 - 8s/epoch - 23ms/step\n",
            "Epoch 128/200\n",
            "354/354 - 8s - loss: 2.0437 - accuracy: 0.5067 - 8s/epoch - 23ms/step\n",
            "Epoch 129/200\n",
            "354/354 - 8s - loss: 2.0124 - accuracy: 0.5183 - 8s/epoch - 23ms/step\n",
            "Epoch 130/200\n",
            "354/354 - 8s - loss: 2.0039 - accuracy: 0.5170 - 8s/epoch - 23ms/step\n",
            "Epoch 131/200\n",
            "354/354 - 8s - loss: 2.0044 - accuracy: 0.5202 - 8s/epoch - 23ms/step\n",
            "Epoch 132/200\n",
            "354/354 - 8s - loss: 1.9884 - accuracy: 0.5191 - 8s/epoch - 23ms/step\n",
            "Epoch 133/200\n",
            "354/354 - 8s - loss: 1.9890 - accuracy: 0.5171 - 8s/epoch - 23ms/step\n",
            "Epoch 134/200\n",
            "354/354 - 8s - loss: 1.9682 - accuracy: 0.5228 - 8s/epoch - 23ms/step\n",
            "Epoch 135/200\n",
            "354/354 - 8s - loss: 1.9479 - accuracy: 0.5249 - 8s/epoch - 23ms/step\n",
            "Epoch 136/200\n",
            "354/354 - 8s - loss: 1.9295 - accuracy: 0.5331 - 8s/epoch - 23ms/step\n",
            "Epoch 137/200\n",
            "354/354 - 8s - loss: 1.9185 - accuracy: 0.5402 - 8s/epoch - 23ms/step\n",
            "Epoch 138/200\n",
            "354/354 - 8s - loss: 1.8970 - accuracy: 0.5366 - 8s/epoch - 23ms/step\n",
            "Epoch 139/200\n",
            "354/354 - 8s - loss: 1.9115 - accuracy: 0.5369 - 8s/epoch - 23ms/step\n",
            "Epoch 140/200\n",
            "354/354 - 8s - loss: 1.8870 - accuracy: 0.5395 - 8s/epoch - 23ms/step\n",
            "Epoch 141/200\n",
            "354/354 - 8s - loss: 1.8807 - accuracy: 0.5415 - 8s/epoch - 23ms/step\n",
            "Epoch 142/200\n",
            "354/354 - 8s - loss: 1.8629 - accuracy: 0.5477 - 8s/epoch - 23ms/step\n",
            "Epoch 143/200\n",
            "354/354 - 8s - loss: 1.9152 - accuracy: 0.5353 - 8s/epoch - 23ms/step\n",
            "Epoch 144/200\n",
            "354/354 - 8s - loss: 1.8563 - accuracy: 0.5487 - 8s/epoch - 23ms/step\n",
            "Epoch 145/200\n",
            "354/354 - 8s - loss: 1.8160 - accuracy: 0.5572 - 8s/epoch - 23ms/step\n",
            "Epoch 146/200\n",
            "354/354 - 8s - loss: 1.7964 - accuracy: 0.5621 - 8s/epoch - 23ms/step\n",
            "Epoch 147/200\n",
            "354/354 - 8s - loss: 1.7970 - accuracy: 0.5629 - 8s/epoch - 23ms/step\n",
            "Epoch 148/200\n",
            "354/354 - 8s - loss: 1.7746 - accuracy: 0.5705 - 8s/epoch - 23ms/step\n",
            "Epoch 149/200\n",
            "354/354 - 8s - loss: 1.7667 - accuracy: 0.5673 - 8s/epoch - 23ms/step\n",
            "Epoch 150/200\n",
            "354/354 - 8s - loss: 1.7603 - accuracy: 0.5693 - 8s/epoch - 23ms/step\n",
            "Epoch 151/200\n",
            "354/354 - 8s - loss: 1.7498 - accuracy: 0.5699 - 8s/epoch - 23ms/step\n",
            "Epoch 152/200\n",
            "354/354 - 8s - loss: 1.7377 - accuracy: 0.5766 - 8s/epoch - 23ms/step\n",
            "Epoch 153/200\n",
            "354/354 - 8s - loss: 1.7379 - accuracy: 0.5692 - 8s/epoch - 22ms/step\n",
            "Epoch 154/200\n",
            "354/354 - 8s - loss: 1.7156 - accuracy: 0.5792 - 8s/epoch - 23ms/step\n",
            "Epoch 155/200\n",
            "354/354 - 8s - loss: 1.7210 - accuracy: 0.5768 - 8s/epoch - 23ms/step\n",
            "Epoch 156/200\n",
            "354/354 - 8s - loss: 1.7159 - accuracy: 0.5742 - 8s/epoch - 23ms/step\n",
            "Epoch 157/200\n",
            "354/354 - 8s - loss: 1.6856 - accuracy: 0.5848 - 8s/epoch - 23ms/step\n",
            "Epoch 158/200\n",
            "354/354 - 8s - loss: 1.6947 - accuracy: 0.5861 - 8s/epoch - 23ms/step\n",
            "Epoch 159/200\n",
            "354/354 - 8s - loss: 1.6833 - accuracy: 0.5897 - 8s/epoch - 23ms/step\n",
            "Epoch 160/200\n",
            "354/354 - 8s - loss: 1.6431 - accuracy: 0.5945 - 8s/epoch - 23ms/step\n",
            "Epoch 161/200\n",
            "354/354 - 8s - loss: 1.6379 - accuracy: 0.5978 - 8s/epoch - 23ms/step\n",
            "Epoch 162/200\n",
            "354/354 - 8s - loss: 1.6460 - accuracy: 0.5953 - 8s/epoch - 23ms/step\n",
            "Epoch 163/200\n",
            "354/354 - 8s - loss: 1.6261 - accuracy: 0.6000 - 8s/epoch - 23ms/step\n",
            "Epoch 164/200\n",
            "354/354 - 8s - loss: 1.6060 - accuracy: 0.6073 - 8s/epoch - 23ms/step\n",
            "Epoch 165/200\n",
            "354/354 - 8s - loss: 1.5999 - accuracy: 0.6086 - 8s/epoch - 23ms/step\n",
            "Epoch 166/200\n",
            "354/354 - 8s - loss: 1.6011 - accuracy: 0.6008 - 8s/epoch - 23ms/step\n",
            "Epoch 167/200\n",
            "354/354 - 8s - loss: 1.5819 - accuracy: 0.6079 - 8s/epoch - 23ms/step\n",
            "Epoch 168/200\n",
            "354/354 - 8s - loss: 1.5964 - accuracy: 0.6041 - 8s/epoch - 23ms/step\n",
            "Epoch 169/200\n",
            "354/354 - 8s - loss: 1.5912 - accuracy: 0.6062 - 8s/epoch - 23ms/step\n",
            "Epoch 170/200\n",
            "354/354 - 8s - loss: 1.5493 - accuracy: 0.6164 - 8s/epoch - 23ms/step\n",
            "Epoch 171/200\n",
            "354/354 - 8s - loss: 1.5545 - accuracy: 0.6147 - 8s/epoch - 23ms/step\n",
            "Epoch 172/200\n",
            "354/354 - 8s - loss: 1.5223 - accuracy: 0.6259 - 8s/epoch - 23ms/step\n",
            "Epoch 173/200\n",
            "354/354 - 8s - loss: 1.5335 - accuracy: 0.6264 - 8s/epoch - 23ms/step\n",
            "Epoch 174/200\n",
            "354/354 - 8s - loss: 1.5144 - accuracy: 0.6216 - 8s/epoch - 23ms/step\n",
            "Epoch 175/200\n",
            "354/354 - 8s - loss: 1.5085 - accuracy: 0.6262 - 8s/epoch - 23ms/step\n",
            "Epoch 176/200\n",
            "354/354 - 8s - loss: 1.4961 - accuracy: 0.6290 - 8s/epoch - 23ms/step\n",
            "Epoch 177/200\n",
            "354/354 - 8s - loss: 1.4828 - accuracy: 0.6321 - 8s/epoch - 23ms/step\n",
            "Epoch 178/200\n",
            "354/354 - 8s - loss: 1.4863 - accuracy: 0.6343 - 8s/epoch - 23ms/step\n",
            "Epoch 179/200\n",
            "354/354 - 8s - loss: 1.4730 - accuracy: 0.6387 - 8s/epoch - 23ms/step\n",
            "Epoch 180/200\n",
            "354/354 - 8s - loss: 1.4461 - accuracy: 0.6437 - 8s/epoch - 23ms/step\n",
            "Epoch 181/200\n",
            "354/354 - 8s - loss: 1.4498 - accuracy: 0.6411 - 8s/epoch - 23ms/step\n",
            "Epoch 182/200\n",
            "354/354 - 8s - loss: 1.4556 - accuracy: 0.6361 - 8s/epoch - 23ms/step\n",
            "Epoch 183/200\n",
            "354/354 - 8s - loss: 1.4388 - accuracy: 0.6405 - 8s/epoch - 23ms/step\n",
            "Epoch 184/200\n",
            "354/354 - 8s - loss: 1.4386 - accuracy: 0.6447 - 8s/epoch - 23ms/step\n",
            "Epoch 185/200\n",
            "354/354 - 8s - loss: 1.4537 - accuracy: 0.6388 - 8s/epoch - 23ms/step\n",
            "Epoch 186/200\n",
            "354/354 - 8s - loss: 1.4154 - accuracy: 0.6490 - 8s/epoch - 23ms/step\n",
            "Epoch 187/200\n",
            "354/354 - 8s - loss: 1.4030 - accuracy: 0.6509 - 8s/epoch - 23ms/step\n",
            "Epoch 188/200\n",
            "354/354 - 8s - loss: 1.4094 - accuracy: 0.6508 - 8s/epoch - 23ms/step\n",
            "Epoch 189/200\n",
            "354/354 - 8s - loss: 1.3810 - accuracy: 0.6559 - 8s/epoch - 24ms/step\n",
            "Epoch 190/200\n",
            "354/354 - 8s - loss: 1.3634 - accuracy: 0.6639 - 8s/epoch - 23ms/step\n",
            "Epoch 191/200\n",
            "354/354 - 8s - loss: 1.3687 - accuracy: 0.6617 - 8s/epoch - 23ms/step\n",
            "Epoch 192/200\n",
            "354/354 - 8s - loss: 1.3980 - accuracy: 0.6475 - 8s/epoch - 23ms/step\n",
            "Epoch 193/200\n",
            "354/354 - 8s - loss: 1.3612 - accuracy: 0.6622 - 8s/epoch - 23ms/step\n",
            "Epoch 194/200\n",
            "354/354 - 8s - loss: 1.3310 - accuracy: 0.6677 - 8s/epoch - 23ms/step\n",
            "Epoch 195/200\n",
            "354/354 - 9s - loss: 1.3312 - accuracy: 0.6706 - 9s/epoch - 24ms/step\n",
            "Epoch 196/200\n",
            "354/354 - 8s - loss: 1.3211 - accuracy: 0.6752 - 8s/epoch - 23ms/step\n",
            "Epoch 197/200\n",
            "354/354 - 8s - loss: 1.3272 - accuracy: 0.6717 - 8s/epoch - 23ms/step\n",
            "Epoch 198/200\n",
            "354/354 - 8s - loss: 1.3208 - accuracy: 0.6699 - 8s/epoch - 23ms/step\n",
            "Epoch 199/200\n",
            "354/354 - 8s - loss: 1.3076 - accuracy: 0.6711 - 8s/epoch - 23ms/step\n",
            "Epoch 200/200\n",
            "354/354 - 8s - loss: 1.3017 - accuracy: 0.6769 - 8s/epoch - 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0059ba9390>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mobydic_model.h5')"
      ],
      "metadata": {
        "id": "rO-bgPG-jI1g"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dump(tokenizer, open('simpleTokenizer', 'wb'))"
      ],
      "metadata": {
        "id": "SnM6PofKjVhv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "  output_text = []\n",
        "  input_text = seed_text\n",
        "  for i in range(num_gen_words):\n",
        "    encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "    pad_encoded = tf.keras.preprocessing.sequence.pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "    pred_word = model.predict(pad_encoded, verbose=0)[0]\n",
        "    pred_word_ind = np.argmax(pred_word)\n",
        "    pred_word = tokenizer.index_word[pred_word_ind]\n",
        "    input_text += ' '+pred_word\n",
        "    output_text.append(pred_word)\n",
        "  return ' '.join(output_text)"
      ],
      "metadata": {
        "id": "fsevAqi8jbwT"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_gen_words = 20\n",
        "n = np.random.randint(0, len(text_sequences))\n",
        "generate_text(model, tokenizer, seq_len, ' '.join(text_sequences[n]), num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tu_qGhvHlU5t",
        "outputId": "56cae20a-f043-43fc-fde8-a8f209da59b1"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'aggregated years stand war than ye this harpooneer might be and exactly try the piece of knowing boots of him'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=32, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0xdCeX3nx_w",
        "outputId": "9066456f-2a2e-4513-d763-323333753fc4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "354/354 - 8s - loss: 1.3031 - accuracy: 0.6761 - 8s/epoch - 23ms/step\n",
            "Epoch 2/100\n",
            "354/354 - 8s - loss: 1.3128 - accuracy: 0.6713 - 8s/epoch - 23ms/step\n",
            "Epoch 3/100\n",
            "354/354 - 8s - loss: 1.2964 - accuracy: 0.6795 - 8s/epoch - 23ms/step\n",
            "Epoch 4/100\n",
            "354/354 - 8s - loss: 1.2651 - accuracy: 0.6858 - 8s/epoch - 23ms/step\n",
            "Epoch 5/100\n",
            "354/354 - 8s - loss: 1.2750 - accuracy: 0.6818 - 8s/epoch - 23ms/step\n",
            "Epoch 6/100\n",
            "354/354 - 8s - loss: 1.2462 - accuracy: 0.6910 - 8s/epoch - 23ms/step\n",
            "Epoch 7/100\n",
            "354/354 - 8s - loss: 1.2508 - accuracy: 0.6844 - 8s/epoch - 23ms/step\n",
            "Epoch 8/100\n",
            "354/354 - 8s - loss: 1.2353 - accuracy: 0.6917 - 8s/epoch - 23ms/step\n",
            "Epoch 9/100\n",
            "354/354 - 8s - loss: 1.2318 - accuracy: 0.6932 - 8s/epoch - 23ms/step\n",
            "Epoch 10/100\n",
            "354/354 - 8s - loss: 1.2352 - accuracy: 0.6933 - 8s/epoch - 23ms/step\n",
            "Epoch 11/100\n",
            "354/354 - 8s - loss: 1.2122 - accuracy: 0.7016 - 8s/epoch - 23ms/step\n",
            "Epoch 12/100\n",
            "354/354 - 8s - loss: 1.2036 - accuracy: 0.6993 - 8s/epoch - 23ms/step\n",
            "Epoch 13/100\n",
            "354/354 - 8s - loss: 1.2143 - accuracy: 0.6968 - 8s/epoch - 23ms/step\n",
            "Epoch 14/100\n",
            "354/354 - 8s - loss: 1.2145 - accuracy: 0.6949 - 8s/epoch - 23ms/step\n",
            "Epoch 15/100\n",
            "354/354 - 8s - loss: 1.1754 - accuracy: 0.7075 - 8s/epoch - 23ms/step\n",
            "Epoch 16/100\n",
            "354/354 - 8s - loss: 1.1823 - accuracy: 0.7077 - 8s/epoch - 23ms/step\n",
            "Epoch 17/100\n",
            "354/354 - 8s - loss: 1.1735 - accuracy: 0.7071 - 8s/epoch - 23ms/step\n",
            "Epoch 18/100\n",
            "354/354 - 8s - loss: 1.1768 - accuracy: 0.7059 - 8s/epoch - 23ms/step\n",
            "Epoch 19/100\n",
            "354/354 - 8s - loss: 1.1669 - accuracy: 0.7107 - 8s/epoch - 23ms/step\n",
            "Epoch 20/100\n",
            "354/354 - 8s - loss: 1.1793 - accuracy: 0.7046 - 8s/epoch - 23ms/step\n",
            "Epoch 21/100\n",
            "354/354 - 8s - loss: 1.1512 - accuracy: 0.7148 - 8s/epoch - 23ms/step\n",
            "Epoch 22/100\n",
            "354/354 - 8s - loss: 1.1193 - accuracy: 0.7228 - 8s/epoch - 23ms/step\n",
            "Epoch 23/100\n",
            "354/354 - 8s - loss: 1.1320 - accuracy: 0.7174 - 8s/epoch - 23ms/step\n",
            "Epoch 24/100\n",
            "354/354 - 8s - loss: 1.1398 - accuracy: 0.7175 - 8s/epoch - 23ms/step\n",
            "Epoch 25/100\n",
            "354/354 - 8s - loss: 1.1332 - accuracy: 0.7161 - 8s/epoch - 23ms/step\n",
            "Epoch 26/100\n",
            "354/354 - 8s - loss: 1.1240 - accuracy: 0.7218 - 8s/epoch - 23ms/step\n",
            "Epoch 27/100\n",
            "354/354 - 8s - loss: 1.0918 - accuracy: 0.7263 - 8s/epoch - 23ms/step\n",
            "Epoch 28/100\n",
            "354/354 - 8s - loss: 1.1178 - accuracy: 0.7184 - 8s/epoch - 23ms/step\n",
            "Epoch 29/100\n",
            "354/354 - 8s - loss: 1.1070 - accuracy: 0.7221 - 8s/epoch - 23ms/step\n",
            "Epoch 30/100\n",
            "354/354 - 8s - loss: 1.0781 - accuracy: 0.7334 - 8s/epoch - 23ms/step\n",
            "Epoch 31/100\n",
            "354/354 - 8s - loss: 1.0655 - accuracy: 0.7370 - 8s/epoch - 23ms/step\n",
            "Epoch 32/100\n",
            "354/354 - 8s - loss: 1.0768 - accuracy: 0.7321 - 8s/epoch - 23ms/step\n",
            "Epoch 33/100\n",
            "354/354 - 8s - loss: 1.1156 - accuracy: 0.7217 - 8s/epoch - 23ms/step\n",
            "Epoch 34/100\n",
            "354/354 - 8s - loss: 1.0990 - accuracy: 0.7227 - 8s/epoch - 23ms/step\n",
            "Epoch 35/100\n",
            "354/354 - 8s - loss: 1.1044 - accuracy: 0.7241 - 8s/epoch - 23ms/step\n",
            "Epoch 36/100\n",
            "354/354 - 8s - loss: 1.0704 - accuracy: 0.7327 - 8s/epoch - 23ms/step\n",
            "Epoch 37/100\n",
            "354/354 - 8s - loss: 1.0443 - accuracy: 0.7375 - 8s/epoch - 23ms/step\n",
            "Epoch 38/100\n",
            "354/354 - 8s - loss: 1.0161 - accuracy: 0.7463 - 8s/epoch - 23ms/step\n",
            "Epoch 39/100\n",
            "354/354 - 8s - loss: 1.0298 - accuracy: 0.7423 - 8s/epoch - 23ms/step\n",
            "Epoch 40/100\n",
            "354/354 - 8s - loss: 1.0121 - accuracy: 0.7530 - 8s/epoch - 23ms/step\n",
            "Epoch 41/100\n",
            "354/354 - 8s - loss: 1.0225 - accuracy: 0.7448 - 8s/epoch - 23ms/step\n",
            "Epoch 42/100\n",
            "354/354 - 8s - loss: 1.0360 - accuracy: 0.7398 - 8s/epoch - 23ms/step\n",
            "Epoch 43/100\n",
            "354/354 - 8s - loss: 1.0403 - accuracy: 0.7400 - 8s/epoch - 23ms/step\n",
            "Epoch 44/100\n",
            "354/354 - 8s - loss: 1.0264 - accuracy: 0.7426 - 8s/epoch - 23ms/step\n",
            "Epoch 45/100\n",
            "354/354 - 8s - loss: 1.0064 - accuracy: 0.7483 - 8s/epoch - 23ms/step\n",
            "Epoch 46/100\n",
            "354/354 - 8s - loss: 1.0001 - accuracy: 0.7558 - 8s/epoch - 23ms/step\n",
            "Epoch 47/100\n",
            "354/354 - 8s - loss: 0.9909 - accuracy: 0.7493 - 8s/epoch - 23ms/step\n",
            "Epoch 48/100\n",
            "354/354 - 8s - loss: 0.9947 - accuracy: 0.7480 - 8s/epoch - 23ms/step\n",
            "Epoch 49/100\n",
            "354/354 - 8s - loss: 0.9993 - accuracy: 0.7507 - 8s/epoch - 23ms/step\n",
            "Epoch 50/100\n",
            "354/354 - 8s - loss: 0.9941 - accuracy: 0.7525 - 8s/epoch - 23ms/step\n",
            "Epoch 51/100\n",
            "354/354 - 8s - loss: 0.9992 - accuracy: 0.7492 - 8s/epoch - 23ms/step\n",
            "Epoch 52/100\n",
            "354/354 - 8s - loss: 0.9882 - accuracy: 0.7538 - 8s/epoch - 23ms/step\n",
            "Epoch 53/100\n",
            "354/354 - 8s - loss: 0.9596 - accuracy: 0.7578 - 8s/epoch - 23ms/step\n",
            "Epoch 54/100\n",
            "354/354 - 8s - loss: 0.9843 - accuracy: 0.7499 - 8s/epoch - 23ms/step\n",
            "Epoch 55/100\n",
            "354/354 - 8s - loss: 0.9408 - accuracy: 0.7656 - 8s/epoch - 23ms/step\n",
            "Epoch 56/100\n",
            "354/354 - 8s - loss: 0.9440 - accuracy: 0.7633 - 8s/epoch - 23ms/step\n",
            "Epoch 57/100\n",
            "354/354 - 8s - loss: 0.9267 - accuracy: 0.7727 - 8s/epoch - 23ms/step\n",
            "Epoch 58/100\n",
            "354/354 - 8s - loss: 0.9273 - accuracy: 0.7677 - 8s/epoch - 23ms/step\n",
            "Epoch 59/100\n",
            "354/354 - 8s - loss: 0.9246 - accuracy: 0.7654 - 8s/epoch - 23ms/step\n",
            "Epoch 60/100\n",
            "354/354 - 8s - loss: 0.9801 - accuracy: 0.7493 - 8s/epoch - 23ms/step\n",
            "Epoch 61/100\n",
            "354/354 - 8s - loss: 0.9451 - accuracy: 0.7636 - 8s/epoch - 24ms/step\n",
            "Epoch 62/100\n",
            "354/354 - 8s - loss: 0.9152 - accuracy: 0.7713 - 8s/epoch - 24ms/step\n",
            "Epoch 63/100\n",
            "354/354 - 8s - loss: 0.9415 - accuracy: 0.7659 - 8s/epoch - 24ms/step\n",
            "Epoch 64/100\n",
            "354/354 - 8s - loss: 0.9464 - accuracy: 0.7616 - 8s/epoch - 24ms/step\n",
            "Epoch 65/100\n",
            "354/354 - 8s - loss: 0.9308 - accuracy: 0.7708 - 8s/epoch - 23ms/step\n",
            "Epoch 66/100\n",
            "354/354 - 8s - loss: 0.9149 - accuracy: 0.7694 - 8s/epoch - 23ms/step\n",
            "Epoch 67/100\n",
            "354/354 - 8s - loss: 0.8764 - accuracy: 0.7812 - 8s/epoch - 23ms/step\n",
            "Epoch 68/100\n",
            "354/354 - 8s - loss: 0.8729 - accuracy: 0.7829 - 8s/epoch - 23ms/step\n",
            "Epoch 69/100\n",
            "354/354 - 8s - loss: 0.8695 - accuracy: 0.7836 - 8s/epoch - 23ms/step\n",
            "Epoch 70/100\n",
            "354/354 - 8s - loss: 0.9192 - accuracy: 0.7680 - 8s/epoch - 23ms/step\n",
            "Epoch 71/100\n",
            "354/354 - 8s - loss: 0.8960 - accuracy: 0.7723 - 8s/epoch - 23ms/step\n",
            "Epoch 72/100\n",
            "354/354 - 8s - loss: 0.8729 - accuracy: 0.7843 - 8s/epoch - 23ms/step\n",
            "Epoch 73/100\n",
            "354/354 - 8s - loss: 0.8638 - accuracy: 0.7845 - 8s/epoch - 23ms/step\n",
            "Epoch 74/100\n",
            "354/354 - 8s - loss: 0.8789 - accuracy: 0.7775 - 8s/epoch - 23ms/step\n",
            "Epoch 75/100\n",
            "354/354 - 8s - loss: 0.8791 - accuracy: 0.7778 - 8s/epoch - 23ms/step\n",
            "Epoch 76/100\n",
            "354/354 - 8s - loss: 0.8754 - accuracy: 0.7789 - 8s/epoch - 23ms/step\n",
            "Epoch 77/100\n",
            "354/354 - 8s - loss: 0.8557 - accuracy: 0.7850 - 8s/epoch - 23ms/step\n",
            "Epoch 78/100\n",
            "354/354 - 8s - loss: 0.8278 - accuracy: 0.7976 - 8s/epoch - 23ms/step\n",
            "Epoch 79/100\n",
            "354/354 - 8s - loss: 0.8255 - accuracy: 0.7944 - 8s/epoch - 23ms/step\n",
            "Epoch 80/100\n",
            "354/354 - 8s - loss: 0.8295 - accuracy: 0.7914 - 8s/epoch - 23ms/step\n",
            "Epoch 81/100\n",
            "354/354 - 8s - loss: 0.8278 - accuracy: 0.7962 - 8s/epoch - 23ms/step\n",
            "Epoch 82/100\n",
            "354/354 - 8s - loss: 0.8446 - accuracy: 0.7887 - 8s/epoch - 23ms/step\n",
            "Epoch 83/100\n",
            "354/354 - 8s - loss: 0.8922 - accuracy: 0.7712 - 8s/epoch - 23ms/step\n",
            "Epoch 84/100\n",
            "354/354 - 8s - loss: 0.8278 - accuracy: 0.7924 - 8s/epoch - 23ms/step\n",
            "Epoch 85/100\n",
            "354/354 - 8s - loss: 0.8014 - accuracy: 0.8007 - 8s/epoch - 23ms/step\n",
            "Epoch 86/100\n",
            "354/354 - 8s - loss: 0.8039 - accuracy: 0.7994 - 8s/epoch - 23ms/step\n",
            "Epoch 87/100\n",
            "354/354 - 8s - loss: 0.8052 - accuracy: 0.7980 - 8s/epoch - 23ms/step\n",
            "Epoch 88/100\n",
            "354/354 - 8s - loss: 0.7969 - accuracy: 0.7996 - 8s/epoch - 23ms/step\n",
            "Epoch 89/100\n",
            "354/354 - 8s - loss: 0.7926 - accuracy: 0.7981 - 8s/epoch - 23ms/step\n",
            "Epoch 90/100\n",
            "354/354 - 8s - loss: 0.8032 - accuracy: 0.7954 - 8s/epoch - 23ms/step\n",
            "Epoch 91/100\n",
            "354/354 - 8s - loss: 0.7870 - accuracy: 0.8021 - 8s/epoch - 23ms/step\n",
            "Epoch 92/100\n",
            "354/354 - 8s - loss: 0.7913 - accuracy: 0.7984 - 8s/epoch - 23ms/step\n",
            "Epoch 93/100\n",
            "354/354 - 8s - loss: 0.7861 - accuracy: 0.8016 - 8s/epoch - 23ms/step\n",
            "Epoch 94/100\n",
            "354/354 - 8s - loss: 0.8033 - accuracy: 0.7989 - 8s/epoch - 23ms/step\n",
            "Epoch 95/100\n",
            "354/354 - 8s - loss: 0.8059 - accuracy: 0.7964 - 8s/epoch - 23ms/step\n",
            "Epoch 96/100\n",
            "354/354 - 8s - loss: 0.7847 - accuracy: 0.8039 - 8s/epoch - 23ms/step\n",
            "Epoch 97/100\n",
            "354/354 - 8s - loss: 0.7761 - accuracy: 0.8062 - 8s/epoch - 23ms/step\n",
            "Epoch 98/100\n",
            "354/354 - 8s - loss: 0.7485 - accuracy: 0.8147 - 8s/epoch - 23ms/step\n",
            "Epoch 99/100\n",
            "354/354 - 8s - loss: 0.7939 - accuracy: 0.7992 - 8s/epoch - 23ms/step\n",
            "Epoch 100/100\n",
            "354/354 - 8s - loss: 0.8592 - accuracy: 0.7814 - 8s/epoch - 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0059921250>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_gen_words = 40\n",
        "n = np.random.randint(0, len(text_sequences))\n",
        "generate_text(model, tokenizer, seq_len, ' '.join(text_sequences[n]), num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "MvXucMEOnzoT",
        "outputId": "0adf7b86-2cfe-4995-a117-3658ff80bd00"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i never unaccountable hours and had not help the decks in anxious sort of fooling it from what i told it for he continued the captain and to the answer i am two and nine at my bit of short'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=32, epochs=100, verbose=2)"
      ],
      "metadata": {
        "id": "kM_W-VOfsFQ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e3103c-634c-4c16-b871-d52a15f2013e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "354/354 - 8s - loss: 0.7558 - accuracy: 0.8128 - 8s/epoch - 23ms/step\n",
            "Epoch 2/100\n",
            "354/354 - 8s - loss: 0.7329 - accuracy: 0.8169 - 8s/epoch - 23ms/step\n",
            "Epoch 3/100\n",
            "354/354 - 8s - loss: 0.7533 - accuracy: 0.8122 - 8s/epoch - 23ms/step\n",
            "Epoch 4/100\n",
            "354/354 - 8s - loss: 0.7293 - accuracy: 0.8211 - 8s/epoch - 24ms/step\n",
            "Epoch 5/100\n",
            "354/354 - 8s - loss: 0.7326 - accuracy: 0.8192 - 8s/epoch - 23ms/step\n",
            "Epoch 6/100\n",
            "354/354 - 8s - loss: 0.7416 - accuracy: 0.8119 - 8s/epoch - 23ms/step\n",
            "Epoch 7/100\n",
            "354/354 - 8s - loss: 0.7505 - accuracy: 0.8120 - 8s/epoch - 23ms/step\n",
            "Epoch 8/100\n",
            "354/354 - 8s - loss: 0.7325 - accuracy: 0.8221 - 8s/epoch - 23ms/step\n",
            "Epoch 9/100\n",
            "354/354 - 8s - loss: 0.7131 - accuracy: 0.8230 - 8s/epoch - 23ms/step\n",
            "Epoch 10/100\n",
            "354/354 - 8s - loss: 0.7331 - accuracy: 0.8134 - 8s/epoch - 23ms/step\n",
            "Epoch 11/100\n",
            "354/354 - 8s - loss: 0.7835 - accuracy: 0.8002 - 8s/epoch - 23ms/step\n",
            "Epoch 12/100\n",
            "354/354 - 8s - loss: 0.7418 - accuracy: 0.8075 - 8s/epoch - 23ms/step\n",
            "Epoch 13/100\n",
            "354/354 - 8s - loss: 0.7055 - accuracy: 0.8249 - 8s/epoch - 23ms/step\n",
            "Epoch 14/100\n",
            "354/354 - 8s - loss: 0.6624 - accuracy: 0.8377 - 8s/epoch - 23ms/step\n",
            "Epoch 15/100\n",
            "354/354 - 8s - loss: 0.7105 - accuracy: 0.8236 - 8s/epoch - 23ms/step\n",
            "Epoch 16/100\n",
            "354/354 - 8s - loss: 0.6929 - accuracy: 0.8280 - 8s/epoch - 23ms/step\n",
            "Epoch 17/100\n",
            "354/354 - 8s - loss: 0.7147 - accuracy: 0.8200 - 8s/epoch - 23ms/step\n",
            "Epoch 18/100\n",
            "354/354 - 8s - loss: 0.6936 - accuracy: 0.8234 - 8s/epoch - 23ms/step\n",
            "Epoch 19/100\n",
            "354/354 - 8s - loss: 0.6605 - accuracy: 0.8363 - 8s/epoch - 23ms/step\n",
            "Epoch 20/100\n",
            "354/354 - 8s - loss: 0.6833 - accuracy: 0.8259 - 8s/epoch - 23ms/step\n",
            "Epoch 21/100\n",
            "354/354 - 8s - loss: 0.6974 - accuracy: 0.8205 - 8s/epoch - 23ms/step\n",
            "Epoch 22/100\n",
            "354/354 - 8s - loss: 0.6863 - accuracy: 0.8261 - 8s/epoch - 23ms/step\n",
            "Epoch 23/100\n",
            "354/354 - 8s - loss: 0.6882 - accuracy: 0.8262 - 8s/epoch - 23ms/step\n",
            "Epoch 24/100\n",
            "354/354 - 8s - loss: 0.6997 - accuracy: 0.8237 - 8s/epoch - 23ms/step\n",
            "Epoch 25/100\n",
            "354/354 - 8s - loss: 0.6833 - accuracy: 0.8277 - 8s/epoch - 23ms/step\n",
            "Epoch 26/100\n",
            "354/354 - 8s - loss: 0.6623 - accuracy: 0.8376 - 8s/epoch - 23ms/step\n",
            "Epoch 27/100\n",
            "354/354 - 8s - loss: 0.6550 - accuracy: 0.8319 - 8s/epoch - 23ms/step\n",
            "Epoch 28/100\n",
            "354/354 - 8s - loss: 0.6529 - accuracy: 0.8365 - 8s/epoch - 23ms/step\n",
            "Epoch 29/100\n",
            "354/354 - 8s - loss: 0.6479 - accuracy: 0.8374 - 8s/epoch - 23ms/step\n",
            "Epoch 30/100\n",
            "354/354 - 8s - loss: 0.6325 - accuracy: 0.8428 - 8s/epoch - 24ms/step\n",
            "Epoch 31/100\n",
            "354/354 - 8s - loss: 0.6191 - accuracy: 0.8451 - 8s/epoch - 23ms/step\n",
            "Epoch 32/100\n",
            "354/354 - 8s - loss: 0.6503 - accuracy: 0.8353 - 8s/epoch - 23ms/step\n",
            "Epoch 33/100\n",
            "354/354 - 8s - loss: 0.6665 - accuracy: 0.8308 - 8s/epoch - 23ms/step\n",
            "Epoch 34/100\n",
            "354/354 - 8s - loss: 0.6788 - accuracy: 0.8289 - 8s/epoch - 23ms/step\n",
            "Epoch 35/100\n",
            "354/354 - 8s - loss: 0.6402 - accuracy: 0.8357 - 8s/epoch - 23ms/step\n",
            "Epoch 36/100\n",
            "354/354 - 8s - loss: 0.6153 - accuracy: 0.8462 - 8s/epoch - 23ms/step\n",
            "Epoch 37/100\n",
            "354/354 - 8s - loss: 0.5996 - accuracy: 0.8500 - 8s/epoch - 23ms/step\n",
            "Epoch 38/100\n",
            "354/354 - 8s - loss: 0.6273 - accuracy: 0.8397 - 8s/epoch - 23ms/step\n",
            "Epoch 39/100\n",
            "354/354 - 8s - loss: 0.6099 - accuracy: 0.8467 - 8s/epoch - 23ms/step\n",
            "Epoch 40/100\n",
            "354/354 - 8s - loss: 0.6214 - accuracy: 0.8457 - 8s/epoch - 23ms/step\n",
            "Epoch 41/100\n",
            "354/354 - 8s - loss: 0.6162 - accuracy: 0.8444 - 8s/epoch - 23ms/step\n",
            "Epoch 42/100\n",
            "354/354 - 8s - loss: 0.6453 - accuracy: 0.8360 - 8s/epoch - 23ms/step\n",
            "Epoch 43/100\n",
            "354/354 - 8s - loss: 0.6172 - accuracy: 0.8464 - 8s/epoch - 23ms/step\n",
            "Epoch 44/100\n",
            "354/354 - 8s - loss: 0.5795 - accuracy: 0.8591 - 8s/epoch - 23ms/step\n",
            "Epoch 45/100\n",
            "354/354 - 8s - loss: 0.5776 - accuracy: 0.8568 - 8s/epoch - 23ms/step\n",
            "Epoch 46/100\n",
            "354/354 - 8s - loss: 0.6239 - accuracy: 0.8451 - 8s/epoch - 23ms/step\n",
            "Epoch 47/100\n",
            "354/354 - 8s - loss: 0.6416 - accuracy: 0.8386 - 8s/epoch - 23ms/step\n",
            "Epoch 48/100\n",
            "354/354 - 8s - loss: 0.6193 - accuracy: 0.8434 - 8s/epoch - 23ms/step\n",
            "Epoch 49/100\n",
            "354/354 - 8s - loss: 0.6182 - accuracy: 0.8436 - 8s/epoch - 23ms/step\n",
            "Epoch 50/100\n",
            "354/354 - 8s - loss: 0.6290 - accuracy: 0.8395 - 8s/epoch - 23ms/step\n",
            "Epoch 51/100\n",
            "354/354 - 8s - loss: 0.5853 - accuracy: 0.8527 - 8s/epoch - 23ms/step\n",
            "Epoch 52/100\n",
            "354/354 - 8s - loss: 0.5691 - accuracy: 0.8594 - 8s/epoch - 23ms/step\n",
            "Epoch 53/100\n",
            "354/354 - 8s - loss: 0.5532 - accuracy: 0.8639 - 8s/epoch - 23ms/step\n",
            "Epoch 54/100\n",
            "354/354 - 8s - loss: 0.5679 - accuracy: 0.8579 - 8s/epoch - 23ms/step\n",
            "Epoch 55/100\n",
            "354/354 - 8s - loss: 0.6395 - accuracy: 0.8383 - 8s/epoch - 23ms/step\n",
            "Epoch 56/100\n",
            "354/354 - 8s - loss: 0.5893 - accuracy: 0.8524 - 8s/epoch - 23ms/step\n",
            "Epoch 57/100\n",
            "354/354 - 8s - loss: 0.5495 - accuracy: 0.8647 - 8s/epoch - 23ms/step\n",
            "Epoch 58/100\n",
            "354/354 - 8s - loss: 0.5630 - accuracy: 0.8618 - 8s/epoch - 23ms/step\n",
            "Epoch 59/100\n",
            "354/354 - 8s - loss: 0.5738 - accuracy: 0.8556 - 8s/epoch - 23ms/step\n",
            "Epoch 60/100\n",
            "354/354 - 8s - loss: 0.5463 - accuracy: 0.8630 - 8s/epoch - 23ms/step\n",
            "Epoch 61/100\n",
            "354/354 - 8s - loss: 0.5320 - accuracy: 0.8679 - 8s/epoch - 23ms/step\n",
            "Epoch 62/100\n",
            "354/354 - 8s - loss: 0.5446 - accuracy: 0.8669 - 8s/epoch - 23ms/step\n",
            "Epoch 63/100\n",
            "354/354 - 8s - loss: 0.5608 - accuracy: 0.8594 - 8s/epoch - 23ms/step\n",
            "Epoch 64/100\n",
            "354/354 - 8s - loss: 0.6016 - accuracy: 0.8455 - 8s/epoch - 23ms/step\n",
            "Epoch 65/100\n",
            "354/354 - 8s - loss: 0.5778 - accuracy: 0.8533 - 8s/epoch - 23ms/step\n",
            "Epoch 66/100\n",
            "354/354 - 8s - loss: 0.5420 - accuracy: 0.8648 - 8s/epoch - 23ms/step\n",
            "Epoch 67/100\n",
            "354/354 - 8s - loss: 0.5366 - accuracy: 0.8655 - 8s/epoch - 24ms/step\n",
            "Epoch 68/100\n",
            "354/354 - 8s - loss: 0.5114 - accuracy: 0.8736 - 8s/epoch - 23ms/step\n",
            "Epoch 69/100\n",
            "354/354 - 8s - loss: 0.5402 - accuracy: 0.8653 - 8s/epoch - 23ms/step\n",
            "Epoch 70/100\n",
            "354/354 - 8s - loss: 0.5223 - accuracy: 0.8669 - 8s/epoch - 23ms/step\n",
            "Epoch 71/100\n",
            "354/354 - 8s - loss: 0.5425 - accuracy: 0.8618 - 8s/epoch - 23ms/step\n",
            "Epoch 72/100\n",
            "354/354 - 8s - loss: 0.5639 - accuracy: 0.8592 - 8s/epoch - 23ms/step\n",
            "Epoch 73/100\n",
            "354/354 - 8s - loss: 0.6249 - accuracy: 0.8423 - 8s/epoch - 23ms/step\n",
            "Epoch 74/100\n",
            "354/354 - 8s - loss: 0.5641 - accuracy: 0.8544 - 8s/epoch - 23ms/step\n",
            "Epoch 75/100\n",
            "354/354 - 8s - loss: 0.5112 - accuracy: 0.8743 - 8s/epoch - 23ms/step\n",
            "Epoch 76/100\n",
            "354/354 - 8s - loss: 0.4675 - accuracy: 0.8883 - 8s/epoch - 23ms/step\n",
            "Epoch 77/100\n",
            "354/354 - 8s - loss: 0.4740 - accuracy: 0.8905 - 8s/epoch - 23ms/step\n",
            "Epoch 78/100\n",
            "354/354 - 8s - loss: 0.5147 - accuracy: 0.8717 - 8s/epoch - 23ms/step\n",
            "Epoch 79/100\n",
            "354/354 - 8s - loss: 0.5685 - accuracy: 0.8536 - 8s/epoch - 23ms/step\n",
            "Epoch 80/100\n",
            "354/354 - 8s - loss: 0.5655 - accuracy: 0.8587 - 8s/epoch - 23ms/step\n",
            "Epoch 81/100\n",
            "354/354 - 8s - loss: 0.5181 - accuracy: 0.8736 - 8s/epoch - 23ms/step\n",
            "Epoch 82/100\n",
            "354/354 - 8s - loss: 0.4886 - accuracy: 0.8817 - 8s/epoch - 23ms/step\n",
            "Epoch 83/100\n",
            "354/354 - 8s - loss: 0.4772 - accuracy: 0.8825 - 8s/epoch - 23ms/step\n",
            "Epoch 84/100\n",
            "354/354 - 8s - loss: 0.4519 - accuracy: 0.8919 - 8s/epoch - 23ms/step\n",
            "Epoch 85/100\n",
            "354/354 - 8s - loss: 0.4771 - accuracy: 0.8851 - 8s/epoch - 23ms/step\n",
            "Epoch 86/100\n",
            "354/354 - 8s - loss: 0.5393 - accuracy: 0.8617 - 8s/epoch - 23ms/step\n",
            "Epoch 87/100\n",
            "354/354 - 8s - loss: 0.6415 - accuracy: 0.8322 - 8s/epoch - 23ms/step\n",
            "Epoch 88/100\n",
            "354/354 - 8s - loss: 0.5172 - accuracy: 0.8635 - 8s/epoch - 23ms/step\n",
            "Epoch 89/100\n",
            "354/354 - 8s - loss: 0.4722 - accuracy: 0.8845 - 8s/epoch - 23ms/step\n",
            "Epoch 90/100\n",
            "354/354 - 8s - loss: 0.4454 - accuracy: 0.8929 - 8s/epoch - 23ms/step\n",
            "Epoch 91/100\n",
            "354/354 - 8s - loss: 0.4536 - accuracy: 0.8903 - 8s/epoch - 23ms/step\n",
            "Epoch 92/100\n",
            "354/354 - 8s - loss: 0.4751 - accuracy: 0.8823 - 8s/epoch - 23ms/step\n",
            "Epoch 93/100\n",
            "354/354 - 8s - loss: 0.5149 - accuracy: 0.8682 - 8s/epoch - 23ms/step\n",
            "Epoch 94/100\n",
            "354/354 - 8s - loss: 0.5121 - accuracy: 0.8706 - 8s/epoch - 23ms/step\n",
            "Epoch 95/100\n",
            "354/354 - 8s - loss: 0.4725 - accuracy: 0.8815 - 8s/epoch - 23ms/step\n",
            "Epoch 96/100\n",
            "354/354 - 8s - loss: 0.4623 - accuracy: 0.8868 - 8s/epoch - 23ms/step\n",
            "Epoch 97/100\n",
            "354/354 - 8s - loss: 0.4858 - accuracy: 0.8779 - 8s/epoch - 23ms/step\n",
            "Epoch 98/100\n",
            "354/354 - 8s - loss: 0.5086 - accuracy: 0.8676 - 8s/epoch - 23ms/step\n",
            "Epoch 99/100\n",
            "354/354 - 8s - loss: 0.4869 - accuracy: 0.8754 - 8s/epoch - 23ms/step\n",
            "Epoch 100/100\n",
            "354/354 - 8s - loss: 0.4573 - accuracy: 0.8843 - 8s/epoch - 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f00597a2490>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mobydic_model.h5')\n",
        "num_gen_words = 40\n",
        "n = np.random.randint(0, len(text_sequences))\n",
        "generate_text(model, tokenizer, seq_len, ' '.join(text_sequences[n]), num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "G_LDblypNeDJ",
        "outputId": "e1358015-5f05-4abe-8173-21d64ee24678"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"of spending a sufferable night unless in some other person 's looking but the bench i think the piece of life for hands glided out to those place in him and if it 's turned over upon a grunt and\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=32, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ngV6MfRW_L1",
        "outputId": "4052abb5-3d95-4563-8cc8-6e41582d90fa"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "354/354 - 8s - loss: 0.4524 - accuracy: 0.8850 - 8s/epoch - 23ms/step\n",
            "Epoch 2/100\n",
            "354/354 - 8s - loss: 0.4721 - accuracy: 0.8800 - 8s/epoch - 23ms/step\n",
            "Epoch 3/100\n",
            "354/354 - 8s - loss: 0.4530 - accuracy: 0.8873 - 8s/epoch - 23ms/step\n",
            "Epoch 4/100\n",
            "354/354 - 8s - loss: 0.4611 - accuracy: 0.8860 - 8s/epoch - 24ms/step\n",
            "Epoch 5/100\n",
            "354/354 - 8s - loss: 0.4741 - accuracy: 0.8807 - 8s/epoch - 23ms/step\n",
            "Epoch 6/100\n",
            "354/354 - 8s - loss: 0.4427 - accuracy: 0.8910 - 8s/epoch - 23ms/step\n",
            "Epoch 7/100\n",
            "354/354 - 8s - loss: 0.4480 - accuracy: 0.8879 - 8s/epoch - 23ms/step\n",
            "Epoch 8/100\n",
            "354/354 - 8s - loss: 0.4983 - accuracy: 0.8723 - 8s/epoch - 23ms/step\n",
            "Epoch 9/100\n",
            "354/354 - 8s - loss: 0.4736 - accuracy: 0.8794 - 8s/epoch - 23ms/step\n",
            "Epoch 10/100\n",
            "354/354 - 8s - loss: 0.4286 - accuracy: 0.8919 - 8s/epoch - 23ms/step\n",
            "Epoch 11/100\n",
            "354/354 - 8s - loss: 0.4434 - accuracy: 0.8937 - 8s/epoch - 23ms/step\n",
            "Epoch 12/100\n",
            "354/354 - 8s - loss: 0.4171 - accuracy: 0.8984 - 8s/epoch - 23ms/step\n",
            "Epoch 13/100\n",
            "354/354 - 8s - loss: 0.4043 - accuracy: 0.9016 - 8s/epoch - 23ms/step\n",
            "Epoch 14/100\n",
            "354/354 - 8s - loss: 0.4184 - accuracy: 0.8967 - 8s/epoch - 23ms/step\n",
            "Epoch 15/100\n",
            "354/354 - 8s - loss: 0.4445 - accuracy: 0.8910 - 8s/epoch - 23ms/step\n",
            "Epoch 16/100\n",
            "354/354 - 8s - loss: 0.4550 - accuracy: 0.8847 - 8s/epoch - 23ms/step\n",
            "Epoch 17/100\n",
            "354/354 - 8s - loss: 0.5103 - accuracy: 0.8699 - 8s/epoch - 23ms/step\n",
            "Epoch 18/100\n",
            "354/354 - 8s - loss: 0.4689 - accuracy: 0.8776 - 8s/epoch - 23ms/step\n",
            "Epoch 19/100\n",
            "354/354 - 8s - loss: 0.3995 - accuracy: 0.9007 - 8s/epoch - 23ms/step\n",
            "Epoch 20/100\n",
            "354/354 - 8s - loss: 0.3911 - accuracy: 0.9079 - 8s/epoch - 23ms/step\n",
            "Epoch 21/100\n",
            "354/354 - 8s - loss: 0.4075 - accuracy: 0.9005 - 8s/epoch - 23ms/step\n",
            "Epoch 22/100\n",
            "354/354 - 8s - loss: 0.4430 - accuracy: 0.8889 - 8s/epoch - 23ms/step\n",
            "Epoch 23/100\n",
            "354/354 - 8s - loss: 0.4489 - accuracy: 0.8844 - 8s/epoch - 23ms/step\n",
            "Epoch 24/100\n",
            "354/354 - 8s - loss: 0.4570 - accuracy: 0.8895 - 8s/epoch - 23ms/step\n",
            "Epoch 25/100\n",
            "354/354 - 8s - loss: 0.4527 - accuracy: 0.8877 - 8s/epoch - 23ms/step\n",
            "Epoch 26/100\n",
            "354/354 - 8s - loss: 0.4513 - accuracy: 0.8884 - 8s/epoch - 23ms/step\n",
            "Epoch 27/100\n",
            "354/354 - 8s - loss: 0.4114 - accuracy: 0.8955 - 8s/epoch - 23ms/step\n",
            "Epoch 28/100\n",
            "354/354 - 8s - loss: 0.3939 - accuracy: 0.9021 - 8s/epoch - 23ms/step\n",
            "Epoch 29/100\n",
            "354/354 - 8s - loss: 0.3941 - accuracy: 0.9043 - 8s/epoch - 23ms/step\n",
            "Epoch 30/100\n",
            "354/354 - 8s - loss: 0.4107 - accuracy: 0.9015 - 8s/epoch - 23ms/step\n",
            "Epoch 31/100\n",
            "354/354 - 8s - loss: 0.3885 - accuracy: 0.9026 - 8s/epoch - 23ms/step\n",
            "Epoch 32/100\n",
            "354/354 - 8s - loss: 0.3859 - accuracy: 0.9059 - 8s/epoch - 23ms/step\n",
            "Epoch 33/100\n",
            "354/354 - 8s - loss: 0.4330 - accuracy: 0.8922 - 8s/epoch - 23ms/step\n",
            "Epoch 34/100\n",
            "354/354 - 8s - loss: 0.4048 - accuracy: 0.9012 - 8s/epoch - 23ms/step\n",
            "Epoch 35/100\n",
            "354/354 - 8s - loss: 0.4715 - accuracy: 0.8864 - 8s/epoch - 24ms/step\n",
            "Epoch 36/100\n",
            "354/354 - 8s - loss: 0.4205 - accuracy: 0.8927 - 8s/epoch - 23ms/step\n",
            "Epoch 37/100\n",
            "354/354 - 8s - loss: 0.4276 - accuracy: 0.8947 - 8s/epoch - 23ms/step\n",
            "Epoch 38/100\n",
            "354/354 - 8s - loss: 0.3857 - accuracy: 0.9063 - 8s/epoch - 23ms/step\n",
            "Epoch 39/100\n",
            "354/354 - 8s - loss: 0.3549 - accuracy: 0.9156 - 8s/epoch - 23ms/step\n",
            "Epoch 40/100\n",
            "354/354 - 8s - loss: 0.3860 - accuracy: 0.9053 - 8s/epoch - 23ms/step\n",
            "Epoch 41/100\n",
            "354/354 - 8s - loss: 0.3605 - accuracy: 0.9165 - 8s/epoch - 23ms/step\n",
            "Epoch 42/100\n",
            "354/354 - 8s - loss: 0.3632 - accuracy: 0.9116 - 8s/epoch - 23ms/step\n",
            "Epoch 43/100\n",
            "354/354 - 8s - loss: 0.4027 - accuracy: 0.9006 - 8s/epoch - 23ms/step\n",
            "Epoch 44/100\n",
            "354/354 - 8s - loss: 0.4822 - accuracy: 0.8786 - 8s/epoch - 23ms/step\n",
            "Epoch 45/100\n",
            "354/354 - 8s - loss: 0.4627 - accuracy: 0.8790 - 8s/epoch - 23ms/step\n",
            "Epoch 46/100\n",
            "354/354 - 8s - loss: 0.3999 - accuracy: 0.9020 - 8s/epoch - 23ms/step\n",
            "Epoch 47/100\n",
            "354/354 - 8s - loss: 0.3604 - accuracy: 0.9133 - 8s/epoch - 23ms/step\n",
            "Epoch 48/100\n",
            "354/354 - 8s - loss: 0.3346 - accuracy: 0.9242 - 8s/epoch - 23ms/step\n",
            "Epoch 49/100\n",
            "354/354 - 8s - loss: 0.3285 - accuracy: 0.9187 - 8s/epoch - 23ms/step\n",
            "Epoch 50/100\n",
            "354/354 - 8s - loss: 0.3377 - accuracy: 0.9213 - 8s/epoch - 23ms/step\n",
            "Epoch 51/100\n",
            "354/354 - 8s - loss: 0.4033 - accuracy: 0.9022 - 8s/epoch - 23ms/step\n",
            "Epoch 52/100\n",
            "354/354 - 8s - loss: 0.5727 - accuracy: 0.8487 - 8s/epoch - 23ms/step\n",
            "Epoch 53/100\n",
            "354/354 - 8s - loss: 0.4886 - accuracy: 0.8710 - 8s/epoch - 23ms/step\n",
            "Epoch 54/100\n",
            "354/354 - 8s - loss: 0.3820 - accuracy: 0.9059 - 8s/epoch - 23ms/step\n",
            "Epoch 55/100\n",
            "354/354 - 8s - loss: 0.3135 - accuracy: 0.9298 - 8s/epoch - 23ms/step\n",
            "Epoch 56/100\n",
            "354/354 - 8s - loss: 0.2966 - accuracy: 0.9336 - 8s/epoch - 23ms/step\n",
            "Epoch 57/100\n",
            "354/354 - 8s - loss: 0.3091 - accuracy: 0.9291 - 8s/epoch - 23ms/step\n",
            "Epoch 58/100\n",
            "354/354 - 8s - loss: 0.3452 - accuracy: 0.9143 - 8s/epoch - 23ms/step\n",
            "Epoch 59/100\n",
            "354/354 - 8s - loss: 0.4856 - accuracy: 0.8739 - 8s/epoch - 23ms/step\n",
            "Epoch 60/100\n",
            "354/354 - 8s - loss: 0.4757 - accuracy: 0.8710 - 8s/epoch - 23ms/step\n",
            "Epoch 61/100\n",
            "354/354 - 8s - loss: 0.4062 - accuracy: 0.9005 - 8s/epoch - 23ms/step\n",
            "Epoch 62/100\n",
            "354/354 - 8s - loss: 0.3530 - accuracy: 0.9135 - 8s/epoch - 23ms/step\n",
            "Epoch 63/100\n",
            "354/354 - 8s - loss: 0.3101 - accuracy: 0.9293 - 8s/epoch - 23ms/step\n",
            "Epoch 64/100\n",
            "354/354 - 8s - loss: 0.2862 - accuracy: 0.9371 - 8s/epoch - 23ms/step\n",
            "Epoch 65/100\n",
            "354/354 - 8s - loss: 0.2948 - accuracy: 0.9307 - 8s/epoch - 23ms/step\n",
            "Epoch 66/100\n",
            "354/354 - 8s - loss: 0.3529 - accuracy: 0.9134 - 8s/epoch - 23ms/step\n",
            "Epoch 67/100\n",
            "354/354 - 8s - loss: 0.3739 - accuracy: 0.9043 - 8s/epoch - 23ms/step\n",
            "Epoch 68/100\n",
            "354/354 - 8s - loss: 0.3903 - accuracy: 0.9009 - 8s/epoch - 23ms/step\n",
            "Epoch 69/100\n",
            "354/354 - 8s - loss: 0.3780 - accuracy: 0.9048 - 8s/epoch - 23ms/step\n",
            "Epoch 70/100\n",
            "354/354 - 8s - loss: 0.3781 - accuracy: 0.9026 - 8s/epoch - 23ms/step\n",
            "Epoch 71/100\n",
            "354/354 - 8s - loss: 0.3953 - accuracy: 0.8988 - 8s/epoch - 24ms/step\n",
            "Epoch 72/100\n",
            "354/354 - 8s - loss: 0.3867 - accuracy: 0.9049 - 8s/epoch - 24ms/step\n",
            "Epoch 73/100\n",
            "354/354 - 8s - loss: 0.3328 - accuracy: 0.9182 - 8s/epoch - 23ms/step\n",
            "Epoch 74/100\n",
            "354/354 - 8s - loss: 0.2954 - accuracy: 0.9314 - 8s/epoch - 23ms/step\n",
            "Epoch 75/100\n",
            "354/354 - 8s - loss: 0.2763 - accuracy: 0.9366 - 8s/epoch - 23ms/step\n",
            "Epoch 76/100\n",
            "354/354 - 8s - loss: 0.3525 - accuracy: 0.9132 - 8s/epoch - 23ms/step\n",
            "Epoch 77/100\n",
            "354/354 - 8s - loss: 0.4038 - accuracy: 0.8981 - 8s/epoch - 23ms/step\n",
            "Epoch 78/100\n",
            "354/354 - 8s - loss: 0.3603 - accuracy: 0.9092 - 8s/epoch - 23ms/step\n",
            "Epoch 79/100\n",
            "354/354 - 8s - loss: 0.3654 - accuracy: 0.9074 - 8s/epoch - 23ms/step\n",
            "Epoch 80/100\n",
            "354/354 - 8s - loss: 0.3331 - accuracy: 0.9203 - 8s/epoch - 23ms/step\n",
            "Epoch 81/100\n",
            "354/354 - 8s - loss: 0.3278 - accuracy: 0.9216 - 8s/epoch - 23ms/step\n",
            "Epoch 82/100\n",
            "354/354 - 8s - loss: 0.3245 - accuracy: 0.9196 - 8s/epoch - 23ms/step\n",
            "Epoch 83/100\n",
            "354/354 - 8s - loss: 0.3091 - accuracy: 0.9270 - 8s/epoch - 23ms/step\n",
            "Epoch 84/100\n",
            "354/354 - 8s - loss: 0.2957 - accuracy: 0.9293 - 8s/epoch - 23ms/step\n",
            "Epoch 85/100\n",
            "354/354 - 8s - loss: 0.3159 - accuracy: 0.9211 - 8s/epoch - 23ms/step\n",
            "Epoch 86/100\n",
            "354/354 - 8s - loss: 0.3660 - accuracy: 0.9089 - 8s/epoch - 23ms/step\n",
            "Epoch 87/100\n",
            "354/354 - 8s - loss: 0.4608 - accuracy: 0.8823 - 8s/epoch - 23ms/step\n",
            "Epoch 88/100\n",
            "354/354 - 8s - loss: 0.4060 - accuracy: 0.8982 - 8s/epoch - 23ms/step\n",
            "Epoch 89/100\n",
            "354/354 - 8s - loss: 0.3458 - accuracy: 0.9145 - 8s/epoch - 23ms/step\n",
            "Epoch 90/100\n",
            "354/354 - 8s - loss: 0.2960 - accuracy: 0.9330 - 8s/epoch - 23ms/step\n",
            "Epoch 91/100\n",
            "354/354 - 8s - loss: 0.2877 - accuracy: 0.9342 - 8s/epoch - 23ms/step\n",
            "Epoch 92/100\n",
            "354/354 - 8s - loss: 0.2778 - accuracy: 0.9361 - 8s/epoch - 23ms/step\n",
            "Epoch 93/100\n",
            "354/354 - 8s - loss: 0.2807 - accuracy: 0.9351 - 8s/epoch - 23ms/step\n",
            "Epoch 94/100\n",
            "354/354 - 8s - loss: 0.3439 - accuracy: 0.9115 - 8s/epoch - 23ms/step\n",
            "Epoch 95/100\n",
            "354/354 - 8s - loss: 0.3085 - accuracy: 0.9230 - 8s/epoch - 23ms/step\n",
            "Epoch 96/100\n",
            "354/354 - 8s - loss: 0.3264 - accuracy: 0.9198 - 8s/epoch - 23ms/step\n",
            "Epoch 97/100\n",
            "354/354 - 8s - loss: 0.3584 - accuracy: 0.9117 - 8s/epoch - 23ms/step\n",
            "Epoch 98/100\n",
            "354/354 - 8s - loss: 0.3647 - accuracy: 0.9046 - 8s/epoch - 23ms/step\n",
            "Epoch 99/100\n",
            "354/354 - 8s - loss: 0.3459 - accuracy: 0.9158 - 8s/epoch - 23ms/step\n",
            "Epoch 100/100\n",
            "354/354 - 8s - loss: 0.4913 - accuracy: 0.8841 - 8s/epoch - 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0059ba5850>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mobydic_model.h5')\n",
        "num_gen_words = 80\n",
        "n = np.random.randint(0, len(text_sequences))\n",
        "generate_text(model, tokenizer, seq_len, ' '.join(text_sequences[n]), num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "0qYJtC2bXCsH",
        "outputId": "e68738f0-4de0-4adf-adeb-fd953c5d1bbc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'and that stranger a harpooneer then your objections indefinitely multiply nor was there any earthly reason why i as a sailor should sleep two in a bed at last can instinct slept goes the answer what a neck however my own wooden house there shelf what this shabby teeth house where so wildly other in the overwhelming idea of a tomahawk fish?\"--this almost cases besmoked in all this harpoon air into me into the vengeance voyage of the legs morning'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=32, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeZNQDatac3_",
        "outputId": "5e858a1b-8f87-4de1-e257-cc66b37c840a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "354/354 - 8s - loss: 0.4217 - accuracy: 0.9006 - 8s/epoch - 23ms/step\n",
            "Epoch 2/100\n",
            "354/354 - 8s - loss: 0.3487 - accuracy: 0.9186 - 8s/epoch - 23ms/step\n",
            "Epoch 3/100\n",
            "354/354 - 8s - loss: 0.2617 - accuracy: 0.9431 - 8s/epoch - 23ms/step\n",
            "Epoch 4/100\n",
            "354/354 - 8s - loss: 0.2268 - accuracy: 0.9532 - 8s/epoch - 23ms/step\n",
            "Epoch 5/100\n",
            "354/354 - 8s - loss: 0.2247 - accuracy: 0.9516 - 8s/epoch - 23ms/step\n",
            "Epoch 6/100\n",
            "354/354 - 8s - loss: 0.2509 - accuracy: 0.9456 - 8s/epoch - 23ms/step\n",
            "Epoch 7/100\n",
            "354/354 - 8s - loss: 0.3435 - accuracy: 0.9135 - 8s/epoch - 23ms/step\n",
            "Epoch 8/100\n",
            "354/354 - 8s - loss: 0.3931 - accuracy: 0.8981 - 8s/epoch - 23ms/step\n",
            "Epoch 9/100\n",
            "354/354 - 8s - loss: 0.3548 - accuracy: 0.9055 - 8s/epoch - 23ms/step\n",
            "Epoch 10/100\n",
            "354/354 - 8s - loss: 0.3207 - accuracy: 0.9189 - 8s/epoch - 23ms/step\n",
            "Epoch 11/100\n",
            "354/354 - 8s - loss: 0.2797 - accuracy: 0.9331 - 8s/epoch - 23ms/step\n",
            "Epoch 12/100\n",
            "354/354 - 8s - loss: 0.2673 - accuracy: 0.9393 - 8s/epoch - 23ms/step\n",
            "Epoch 13/100\n",
            "354/354 - 8s - loss: 0.2657 - accuracy: 0.9380 - 8s/epoch - 23ms/step\n",
            "Epoch 14/100\n",
            "354/354 - 8s - loss: 0.2579 - accuracy: 0.9425 - 8s/epoch - 23ms/step\n",
            "Epoch 15/100\n",
            "354/354 - 8s - loss: 0.2684 - accuracy: 0.9364 - 8s/epoch - 23ms/step\n",
            "Epoch 16/100\n",
            "354/354 - 8s - loss: 0.3075 - accuracy: 0.9228 - 8s/epoch - 23ms/step\n",
            "Epoch 17/100\n",
            "354/354 - 8s - loss: 0.3664 - accuracy: 0.9041 - 8s/epoch - 23ms/step\n",
            "Epoch 18/100\n",
            "354/354 - 8s - loss: 0.3356 - accuracy: 0.9141 - 8s/epoch - 23ms/step\n",
            "Epoch 19/100\n",
            "354/354 - 8s - loss: 0.3490 - accuracy: 0.9152 - 8s/epoch - 23ms/step\n",
            "Epoch 20/100\n",
            "354/354 - 8s - loss: 0.3199 - accuracy: 0.9226 - 8s/epoch - 23ms/step\n",
            "Epoch 21/100\n",
            "354/354 - 8s - loss: 0.2666 - accuracy: 0.9348 - 8s/epoch - 23ms/step\n",
            "Epoch 22/100\n",
            "354/354 - 8s - loss: 0.2539 - accuracy: 0.9446 - 8s/epoch - 23ms/step\n",
            "Epoch 23/100\n",
            "354/354 - 8s - loss: 0.2263 - accuracy: 0.9506 - 8s/epoch - 23ms/step\n",
            "Epoch 24/100\n",
            "354/354 - 8s - loss: 0.2348 - accuracy: 0.9491 - 8s/epoch - 23ms/step\n",
            "Epoch 25/100\n",
            "354/354 - 8s - loss: 0.2678 - accuracy: 0.9359 - 8s/epoch - 23ms/step\n",
            "Epoch 26/100\n",
            "354/354 - 8s - loss: 0.4427 - accuracy: 0.8822 - 8s/epoch - 24ms/step\n",
            "Epoch 27/100\n",
            "354/354 - 8s - loss: 0.3546 - accuracy: 0.9076 - 8s/epoch - 23ms/step\n",
            "Epoch 28/100\n",
            "354/354 - 8s - loss: 0.2939 - accuracy: 0.9271 - 8s/epoch - 23ms/step\n",
            "Epoch 29/100\n",
            "354/354 - 8s - loss: 0.2705 - accuracy: 0.9365 - 8s/epoch - 23ms/step\n",
            "Epoch 30/100\n",
            "354/354 - 8s - loss: 0.2326 - accuracy: 0.9479 - 8s/epoch - 23ms/step\n",
            "Epoch 31/100\n",
            "354/354 - 8s - loss: 0.2111 - accuracy: 0.9546 - 8s/epoch - 23ms/step\n",
            "Epoch 32/100\n",
            "354/354 - 8s - loss: 0.2119 - accuracy: 0.9541 - 8s/epoch - 23ms/step\n",
            "Epoch 33/100\n",
            "354/354 - 8s - loss: 0.2224 - accuracy: 0.9518 - 8s/epoch - 23ms/step\n",
            "Epoch 34/100\n",
            "354/354 - 8s - loss: 0.2939 - accuracy: 0.9273 - 8s/epoch - 23ms/step\n",
            "Epoch 35/100\n",
            "354/354 - 8s - loss: 0.3575 - accuracy: 0.9090 - 8s/epoch - 23ms/step\n",
            "Epoch 36/100\n",
            "354/354 - 8s - loss: 0.3779 - accuracy: 0.8997 - 8s/epoch - 23ms/step\n",
            "Epoch 37/100\n",
            "354/354 - 8s - loss: 0.3164 - accuracy: 0.9219 - 8s/epoch - 23ms/step\n",
            "Epoch 38/100\n",
            "354/354 - 8s - loss: 0.2376 - accuracy: 0.9455 - 8s/epoch - 23ms/step\n",
            "Epoch 39/100\n",
            "354/354 - 8s - loss: 0.1997 - accuracy: 0.9591 - 8s/epoch - 23ms/step\n",
            "Epoch 40/100\n",
            "354/354 - 8s - loss: 0.1940 - accuracy: 0.9584 - 8s/epoch - 23ms/step\n",
            "Epoch 41/100\n",
            "354/354 - 8s - loss: 0.2110 - accuracy: 0.9530 - 8s/epoch - 24ms/step\n",
            "Epoch 42/100\n",
            "354/354 - 8s - loss: 0.2742 - accuracy: 0.9325 - 8s/epoch - 23ms/step\n",
            "Epoch 43/100\n",
            "354/354 - 8s - loss: 0.3881 - accuracy: 0.9019 - 8s/epoch - 23ms/step\n",
            "Epoch 44/100\n",
            "354/354 - 8s - loss: 0.3445 - accuracy: 0.9113 - 8s/epoch - 23ms/step\n",
            "Epoch 45/100\n",
            "354/354 - 8s - loss: 0.3234 - accuracy: 0.9167 - 8s/epoch - 23ms/step\n",
            "Epoch 46/100\n",
            "354/354 - 8s - loss: 0.2676 - accuracy: 0.9353 - 8s/epoch - 23ms/step\n",
            "Epoch 47/100\n",
            "354/354 - 8s - loss: 0.2203 - accuracy: 0.9516 - 8s/epoch - 23ms/step\n",
            "Epoch 48/100\n",
            "354/354 - 8s - loss: 0.1968 - accuracy: 0.9580 - 8s/epoch - 23ms/step\n",
            "Epoch 49/100\n",
            "354/354 - 8s - loss: 0.1644 - accuracy: 0.9670 - 8s/epoch - 23ms/step\n",
            "Epoch 50/100\n",
            "354/354 - 8s - loss: 0.1821 - accuracy: 0.9626 - 8s/epoch - 23ms/step\n",
            "Epoch 51/100\n",
            "354/354 - 8s - loss: 0.2845 - accuracy: 0.9301 - 8s/epoch - 23ms/step\n",
            "Epoch 52/100\n",
            "354/354 - 8s - loss: 0.4596 - accuracy: 0.8746 - 8s/epoch - 23ms/step\n",
            "Epoch 53/100\n",
            "354/354 - 8s - loss: 0.4225 - accuracy: 0.8906 - 8s/epoch - 23ms/step\n",
            "Epoch 54/100\n",
            "354/354 - 8s - loss: 0.3530 - accuracy: 0.9128 - 8s/epoch - 23ms/step\n",
            "Epoch 55/100\n",
            "354/354 - 8s - loss: 0.2618 - accuracy: 0.9371 - 8s/epoch - 23ms/step\n",
            "Epoch 56/100\n",
            "354/354 - 8s - loss: 0.2227 - accuracy: 0.9535 - 8s/epoch - 23ms/step\n",
            "Epoch 57/100\n",
            "354/354 - 8s - loss: 0.1895 - accuracy: 0.9638 - 8s/epoch - 23ms/step\n",
            "Epoch 58/100\n",
            "354/354 - 8s - loss: 0.1668 - accuracy: 0.9673 - 8s/epoch - 23ms/step\n",
            "Epoch 59/100\n",
            "354/354 - 8s - loss: 0.1686 - accuracy: 0.9661 - 8s/epoch - 23ms/step\n",
            "Epoch 60/100\n",
            "354/354 - 8s - loss: 0.2472 - accuracy: 0.9416 - 8s/epoch - 22ms/step\n",
            "Epoch 61/100\n",
            "354/354 - 8s - loss: 0.3416 - accuracy: 0.9090 - 8s/epoch - 23ms/step\n",
            "Epoch 62/100\n",
            "354/354 - 8s - loss: 0.3413 - accuracy: 0.9085 - 8s/epoch - 23ms/step\n",
            "Epoch 63/100\n",
            "354/354 - 8s - loss: 0.3102 - accuracy: 0.9219 - 8s/epoch - 23ms/step\n",
            "Epoch 64/100\n",
            "354/354 - 8s - loss: 0.2532 - accuracy: 0.9426 - 8s/epoch - 23ms/step\n",
            "Epoch 65/100\n",
            "354/354 - 8s - loss: 0.1997 - accuracy: 0.9562 - 8s/epoch - 23ms/step\n",
            "Epoch 66/100\n",
            "354/354 - 8s - loss: 0.1903 - accuracy: 0.9592 - 8s/epoch - 23ms/step\n",
            "Epoch 67/100\n",
            "354/354 - 8s - loss: 0.1824 - accuracy: 0.9625 - 8s/epoch - 22ms/step\n",
            "Epoch 68/100\n",
            "354/354 - 8s - loss: 0.2080 - accuracy: 0.9543 - 8s/epoch - 23ms/step\n",
            "Epoch 69/100\n",
            "354/354 - 8s - loss: 0.2637 - accuracy: 0.9355 - 8s/epoch - 23ms/step\n",
            "Epoch 70/100\n",
            "354/354 - 8s - loss: 0.2975 - accuracy: 0.9207 - 8s/epoch - 23ms/step\n",
            "Epoch 71/100\n",
            "354/354 - 8s - loss: 0.3093 - accuracy: 0.9230 - 8s/epoch - 23ms/step\n",
            "Epoch 72/100\n",
            "354/354 - 8s - loss: 0.2769 - accuracy: 0.9310 - 8s/epoch - 23ms/step\n",
            "Epoch 73/100\n",
            "354/354 - 8s - loss: 0.2357 - accuracy: 0.9450 - 8s/epoch - 23ms/step\n",
            "Epoch 74/100\n",
            "354/354 - 8s - loss: 0.2199 - accuracy: 0.9470 - 8s/epoch - 23ms/step\n",
            "Epoch 75/100\n",
            "354/354 - 8s - loss: 0.2516 - accuracy: 0.9408 - 8s/epoch - 23ms/step\n",
            "Epoch 76/100\n",
            "354/354 - 8s - loss: 0.3035 - accuracy: 0.9264 - 8s/epoch - 23ms/step\n",
            "Epoch 77/100\n",
            "354/354 - 8s - loss: 0.2839 - accuracy: 0.9267 - 8s/epoch - 23ms/step\n",
            "Epoch 78/100\n",
            "354/354 - 8s - loss: 0.2048 - accuracy: 0.9525 - 8s/epoch - 24ms/step\n",
            "Epoch 79/100\n",
            "354/354 - 8s - loss: 0.1723 - accuracy: 0.9658 - 8s/epoch - 23ms/step\n",
            "Epoch 80/100\n",
            "354/354 - 8s - loss: 0.1485 - accuracy: 0.9731 - 8s/epoch - 23ms/step\n",
            "Epoch 81/100\n",
            "354/354 - 8s - loss: 0.1678 - accuracy: 0.9641 - 8s/epoch - 23ms/step\n",
            "Epoch 82/100\n",
            "354/354 - 8s - loss: 0.2407 - accuracy: 0.9394 - 8s/epoch - 23ms/step\n",
            "Epoch 83/100\n",
            "354/354 - 8s - loss: 0.3296 - accuracy: 0.9150 - 8s/epoch - 23ms/step\n",
            "Epoch 84/100\n",
            "354/354 - 8s - loss: 0.3423 - accuracy: 0.9135 - 8s/epoch - 23ms/step\n",
            "Epoch 85/100\n",
            "354/354 - 8s - loss: 0.2728 - accuracy: 0.9329 - 8s/epoch - 23ms/step\n",
            "Epoch 86/100\n",
            "354/354 - 8s - loss: 0.2408 - accuracy: 0.9409 - 8s/epoch - 23ms/step\n",
            "Epoch 87/100\n",
            "354/354 - 8s - loss: 0.1955 - accuracy: 0.9551 - 8s/epoch - 23ms/step\n",
            "Epoch 88/100\n",
            "354/354 - 8s - loss: 0.1757 - accuracy: 0.9624 - 8s/epoch - 23ms/step\n",
            "Epoch 89/100\n",
            "354/354 - 8s - loss: 0.1698 - accuracy: 0.9625 - 8s/epoch - 23ms/step\n",
            "Epoch 90/100\n",
            "354/354 - 8s - loss: 0.2288 - accuracy: 0.9484 - 8s/epoch - 23ms/step\n",
            "Epoch 91/100\n",
            "354/354 - 8s - loss: 0.3170 - accuracy: 0.9239 - 8s/epoch - 23ms/step\n",
            "Epoch 92/100\n",
            "354/354 - 8s - loss: 0.2681 - accuracy: 0.9342 - 8s/epoch - 22ms/step\n",
            "Epoch 93/100\n",
            "354/354 - 8s - loss: 0.2326 - accuracy: 0.9460 - 8s/epoch - 23ms/step\n",
            "Epoch 94/100\n",
            "354/354 - 8s - loss: 0.2221 - accuracy: 0.9487 - 8s/epoch - 23ms/step\n",
            "Epoch 95/100\n",
            "354/354 - 8s - loss: 0.1723 - accuracy: 0.9650 - 8s/epoch - 23ms/step\n",
            "Epoch 96/100\n",
            "354/354 - 8s - loss: 0.2354 - accuracy: 0.9470 - 8s/epoch - 23ms/step\n",
            "Epoch 97/100\n",
            "354/354 - 8s - loss: 0.2520 - accuracy: 0.9374 - 8s/epoch - 23ms/step\n",
            "Epoch 98/100\n",
            "354/354 - 8s - loss: 0.2108 - accuracy: 0.9501 - 8s/epoch - 23ms/step\n",
            "Epoch 99/100\n",
            "354/354 - 8s - loss: 0.1841 - accuracy: 0.9572 - 8s/epoch - 23ms/step\n",
            "Epoch 100/100\n",
            "354/354 - 8s - loss: 0.1642 - accuracy: 0.9656 - 8s/epoch - 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0059711410>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mobydic_model.h5')\n",
        "num_gen_words = 80\n",
        "n = np.random.randint(0, len(text_sequences))\n",
        "generate_text(model, tokenizer, seq_len, ' '.join(text_sequences[n]), num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "OT78HDL0am38",
        "outputId": "fe50c146-3f8b-48d5-ba13-7856b52c0186"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"out of the bed and not dreadful the i the the ibis and perhaps queequeg river hand in his uncomfortableness with water his hacking horrifying implement mixed with an poison one meridians chimney leaves at those one on i begged any green deal as there that any sober bedfellow and hand and one there sam i thought paid the middle of the streets received as it was not seem such want once complied in unlacing being found it 's has\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x, y, batch_size=32, epochs=100, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGjSzOcPfHdG",
        "outputId": "e4918959-d250-483e-9248-0788dd502bab"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "354/354 - 8s - loss: 0.1674 - accuracy: 0.9638 - 8s/epoch - 24ms/step\n",
            "Epoch 2/100\n",
            "354/354 - 8s - loss: 0.2275 - accuracy: 0.9449 - 8s/epoch - 24ms/step\n",
            "Epoch 3/100\n",
            "354/354 - 8s - loss: 0.3381 - accuracy: 0.9119 - 8s/epoch - 23ms/step\n",
            "Epoch 4/100\n",
            "354/354 - 8s - loss: 0.3276 - accuracy: 0.9135 - 8s/epoch - 24ms/step\n",
            "Epoch 5/100\n",
            "354/354 - 8s - loss: 0.2743 - accuracy: 0.9342 - 8s/epoch - 24ms/step\n",
            "Epoch 6/100\n",
            "354/354 - 8s - loss: 0.1985 - accuracy: 0.9558 - 8s/epoch - 24ms/step\n",
            "Epoch 7/100\n",
            "354/354 - 8s - loss: 0.1529 - accuracy: 0.9702 - 8s/epoch - 23ms/step\n",
            "Epoch 8/100\n",
            "354/354 - 8s - loss: 0.1497 - accuracy: 0.9723 - 8s/epoch - 23ms/step\n",
            "Epoch 9/100\n",
            "354/354 - 8s - loss: 0.1406 - accuracy: 0.9759 - 8s/epoch - 24ms/step\n",
            "Epoch 10/100\n",
            "354/354 - 8s - loss: 0.1569 - accuracy: 0.9680 - 8s/epoch - 24ms/step\n",
            "Epoch 11/100\n",
            "354/354 - 8s - loss: 0.2597 - accuracy: 0.9316 - 8s/epoch - 24ms/step\n",
            "Epoch 12/100\n",
            "354/354 - 8s - loss: 0.4263 - accuracy: 0.8889 - 8s/epoch - 24ms/step\n",
            "Epoch 13/100\n",
            "354/354 - 8s - loss: 0.2802 - accuracy: 0.9290 - 8s/epoch - 24ms/step\n",
            "Epoch 14/100\n",
            "354/354 - 8s - loss: 0.1982 - accuracy: 0.9548 - 8s/epoch - 23ms/step\n",
            "Epoch 15/100\n",
            "354/354 - 8s - loss: 0.1583 - accuracy: 0.9678 - 8s/epoch - 23ms/step\n",
            "Epoch 16/100\n",
            "354/354 - 8s - loss: 0.1664 - accuracy: 0.9651 - 8s/epoch - 24ms/step\n",
            "Epoch 17/100\n",
            "354/354 - 8s - loss: 0.1530 - accuracy: 0.9686 - 8s/epoch - 23ms/step\n",
            "Epoch 18/100\n",
            "354/354 - 8s - loss: 0.1751 - accuracy: 0.9606 - 8s/epoch - 23ms/step\n",
            "Epoch 19/100\n",
            "354/354 - 8s - loss: 0.2264 - accuracy: 0.9424 - 8s/epoch - 24ms/step\n",
            "Epoch 20/100\n",
            "354/354 - 8s - loss: 0.2465 - accuracy: 0.9362 - 8s/epoch - 23ms/step\n",
            "Epoch 21/100\n",
            "354/354 - 8s - loss: 0.2680 - accuracy: 0.9292 - 8s/epoch - 24ms/step\n",
            "Epoch 22/100\n",
            "354/354 - 8s - loss: 0.2316 - accuracy: 0.9432 - 8s/epoch - 23ms/step\n",
            "Epoch 23/100\n",
            "354/354 - 8s - loss: 0.2104 - accuracy: 0.9493 - 8s/epoch - 24ms/step\n",
            "Epoch 24/100\n",
            "354/354 - 8s - loss: 0.1997 - accuracy: 0.9552 - 8s/epoch - 24ms/step\n",
            "Epoch 25/100\n",
            "354/354 - 8s - loss: 0.1794 - accuracy: 0.9599 - 8s/epoch - 23ms/step\n",
            "Epoch 26/100\n",
            "354/354 - 8s - loss: 0.1628 - accuracy: 0.9627 - 8s/epoch - 24ms/step\n",
            "Epoch 27/100\n",
            "354/354 - 8s - loss: 0.1669 - accuracy: 0.9630 - 8s/epoch - 24ms/step\n",
            "Epoch 28/100\n",
            "354/354 - 8s - loss: 0.2095 - accuracy: 0.9503 - 8s/epoch - 24ms/step\n",
            "Epoch 29/100\n",
            "354/354 - 8s - loss: 0.2687 - accuracy: 0.9313 - 8s/epoch - 24ms/step\n",
            "Epoch 30/100\n",
            "354/354 - 8s - loss: 0.3143 - accuracy: 0.9188 - 8s/epoch - 23ms/step\n",
            "Epoch 31/100\n",
            "354/354 - 8s - loss: 0.2198 - accuracy: 0.9436 - 8s/epoch - 24ms/step\n",
            "Epoch 32/100\n",
            "354/354 - 8s - loss: 0.1483 - accuracy: 0.9676 - 8s/epoch - 24ms/step\n",
            "Epoch 33/100\n",
            "354/354 - 8s - loss: 0.1206 - accuracy: 0.9769 - 8s/epoch - 24ms/step\n",
            "Epoch 34/100\n",
            "354/354 - 8s - loss: 0.1236 - accuracy: 0.9763 - 8s/epoch - 24ms/step\n",
            "Epoch 35/100\n",
            "354/354 - 8s - loss: 0.1287 - accuracy: 0.9734 - 8s/epoch - 24ms/step\n",
            "Epoch 36/100\n",
            "354/354 - 8s - loss: 0.1587 - accuracy: 0.9641 - 8s/epoch - 24ms/step\n",
            "Epoch 37/100\n",
            "354/354 - 8s - loss: 0.3162 - accuracy: 0.9190 - 8s/epoch - 24ms/step\n",
            "Epoch 38/100\n",
            "354/354 - 9s - loss: 0.3774 - accuracy: 0.9006 - 9s/epoch - 24ms/step\n",
            "Epoch 39/100\n",
            "354/354 - 8s - loss: 0.3033 - accuracy: 0.9230 - 8s/epoch - 24ms/step\n",
            "Epoch 40/100\n",
            "354/354 - 8s - loss: 0.1876 - accuracy: 0.9556 - 8s/epoch - 24ms/step\n",
            "Epoch 41/100\n",
            "354/354 - 8s - loss: 0.1295 - accuracy: 0.9774 - 8s/epoch - 24ms/step\n",
            "Epoch 42/100\n",
            "354/354 - 8s - loss: 0.1074 - accuracy: 0.9813 - 8s/epoch - 23ms/step\n",
            "Epoch 43/100\n",
            "354/354 - 8s - loss: 0.1121 - accuracy: 0.9806 - 8s/epoch - 24ms/step\n",
            "Epoch 44/100\n",
            "354/354 - 8s - loss: 0.1455 - accuracy: 0.9685 - 8s/epoch - 24ms/step\n",
            "Epoch 45/100\n",
            "354/354 - 9s - loss: 0.2997 - accuracy: 0.9247 - 9s/epoch - 24ms/step\n",
            "Epoch 46/100\n",
            "354/354 - 9s - loss: 0.2717 - accuracy: 0.9279 - 9s/epoch - 24ms/step\n",
            "Epoch 47/100\n",
            "354/354 - 9s - loss: 0.1849 - accuracy: 0.9560 - 9s/epoch - 25ms/step\n",
            "Epoch 48/100\n",
            "354/354 - 9s - loss: 0.1528 - accuracy: 0.9655 - 9s/epoch - 25ms/step\n",
            "Epoch 49/100\n",
            "354/354 - 9s - loss: 0.1537 - accuracy: 0.9668 - 9s/epoch - 24ms/step\n",
            "Epoch 50/100\n",
            "354/354 - 8s - loss: 0.1749 - accuracy: 0.9607 - 8s/epoch - 24ms/step\n",
            "Epoch 51/100\n",
            "354/354 - 8s - loss: 0.1934 - accuracy: 0.9547 - 8s/epoch - 24ms/step\n",
            "Epoch 52/100\n",
            "354/354 - 8s - loss: 0.1901 - accuracy: 0.9516 - 8s/epoch - 24ms/step\n",
            "Epoch 53/100\n",
            "354/354 - 8s - loss: 0.2038 - accuracy: 0.9524 - 8s/epoch - 24ms/step\n",
            "Epoch 54/100\n",
            "354/354 - 8s - loss: 0.2189 - accuracy: 0.9453 - 8s/epoch - 24ms/step\n",
            "Epoch 55/100\n",
            "354/354 - 8s - loss: 0.1982 - accuracy: 0.9525 - 8s/epoch - 24ms/step\n",
            "Epoch 56/100\n",
            "354/354 - 8s - loss: 0.1909 - accuracy: 0.9537 - 8s/epoch - 24ms/step\n",
            "Epoch 57/100\n",
            "354/354 - 8s - loss: 0.1375 - accuracy: 0.9691 - 8s/epoch - 24ms/step\n",
            "Epoch 58/100\n",
            "354/354 - 8s - loss: 0.1239 - accuracy: 0.9757 - 8s/epoch - 24ms/step\n",
            "Epoch 59/100\n",
            "354/354 - 9s - loss: 0.1838 - accuracy: 0.9557 - 9s/epoch - 24ms/step\n",
            "Epoch 60/100\n",
            "354/354 - 9s - loss: 0.2329 - accuracy: 0.9431 - 9s/epoch - 24ms/step\n",
            "Epoch 61/100\n",
            "354/354 - 8s - loss: 0.2805 - accuracy: 0.9272 - 8s/epoch - 24ms/step\n",
            "Epoch 62/100\n",
            "354/354 - 9s - loss: 0.1958 - accuracy: 0.9501 - 9s/epoch - 24ms/step\n",
            "Epoch 63/100\n",
            "354/354 - 8s - loss: 0.1507 - accuracy: 0.9676 - 8s/epoch - 24ms/step\n",
            "Epoch 64/100\n",
            "354/354 - 8s - loss: 0.1368 - accuracy: 0.9711 - 8s/epoch - 24ms/step\n",
            "Epoch 65/100\n",
            "354/354 - 9s - loss: 0.1140 - accuracy: 0.9781 - 9s/epoch - 24ms/step\n",
            "Epoch 66/100\n",
            "354/354 - 8s - loss: 0.1427 - accuracy: 0.9684 - 8s/epoch - 24ms/step\n",
            "Epoch 67/100\n",
            "354/354 - 8s - loss: 0.1891 - accuracy: 0.9537 - 8s/epoch - 24ms/step\n",
            "Epoch 68/100\n",
            "354/354 - 8s - loss: 0.2726 - accuracy: 0.9304 - 8s/epoch - 24ms/step\n",
            "Epoch 69/100\n",
            "354/354 - 9s - loss: 0.2445 - accuracy: 0.9376 - 9s/epoch - 24ms/step\n",
            "Epoch 70/100\n",
            "354/354 - 8s - loss: 0.1614 - accuracy: 0.9621 - 8s/epoch - 24ms/step\n",
            "Epoch 71/100\n",
            "354/354 - 8s - loss: 0.1405 - accuracy: 0.9692 - 8s/epoch - 24ms/step\n",
            "Epoch 72/100\n",
            "354/354 - 9s - loss: 0.1399 - accuracy: 0.9685 - 9s/epoch - 24ms/step\n",
            "Epoch 73/100\n",
            "354/354 - 8s - loss: 0.1354 - accuracy: 0.9707 - 8s/epoch - 24ms/step\n",
            "Epoch 74/100\n",
            "354/354 - 9s - loss: 0.1176 - accuracy: 0.9743 - 9s/epoch - 24ms/step\n",
            "Epoch 75/100\n",
            "354/354 - 9s - loss: 0.1209 - accuracy: 0.9748 - 9s/epoch - 24ms/step\n",
            "Epoch 76/100\n",
            "354/354 - 9s - loss: 0.2397 - accuracy: 0.9364 - 9s/epoch - 24ms/step\n",
            "Epoch 77/100\n",
            "354/354 - 9s - loss: 0.3007 - accuracy: 0.9221 - 9s/epoch - 24ms/step\n",
            "Epoch 78/100\n",
            "354/354 - 9s - loss: 0.2516 - accuracy: 0.9340 - 9s/epoch - 24ms/step\n",
            "Epoch 79/100\n",
            "354/354 - 8s - loss: 0.1911 - accuracy: 0.9551 - 8s/epoch - 24ms/step\n",
            "Epoch 80/100\n",
            "354/354 - 9s - loss: 0.1248 - accuracy: 0.9728 - 9s/epoch - 24ms/step\n",
            "Epoch 81/100\n",
            "354/354 - 9s - loss: 0.0940 - accuracy: 0.9849 - 9s/epoch - 24ms/step\n",
            "Epoch 82/100\n",
            "354/354 - 9s - loss: 0.0813 - accuracy: 0.9882 - 9s/epoch - 25ms/step\n",
            "Epoch 83/100\n",
            "354/354 - 9s - loss: 0.0720 - accuracy: 0.9905 - 9s/epoch - 24ms/step\n",
            "Epoch 84/100\n",
            "354/354 - 9s - loss: 0.0821 - accuracy: 0.9860 - 9s/epoch - 25ms/step\n",
            "Epoch 85/100\n",
            "354/354 - 9s - loss: 0.2692 - accuracy: 0.9337 - 9s/epoch - 25ms/step\n",
            "Epoch 86/100\n",
            "354/354 - 9s - loss: 0.5009 - accuracy: 0.8724 - 9s/epoch - 24ms/step\n",
            "Epoch 87/100\n",
            "354/354 - 9s - loss: 0.3125 - accuracy: 0.9181 - 9s/epoch - 24ms/step\n",
            "Epoch 88/100\n",
            "354/354 - 8s - loss: 0.1591 - accuracy: 0.9618 - 8s/epoch - 24ms/step\n",
            "Epoch 89/100\n",
            "354/354 - 9s - loss: 0.1001 - accuracy: 0.9816 - 9s/epoch - 24ms/step\n",
            "Epoch 90/100\n",
            "354/354 - 9s - loss: 0.0668 - accuracy: 0.9911 - 9s/epoch - 24ms/step\n",
            "Epoch 91/100\n",
            "354/354 - 9s - loss: 0.0561 - accuracy: 0.9943 - 9s/epoch - 24ms/step\n",
            "Epoch 92/100\n",
            "354/354 - 9s - loss: 0.0522 - accuracy: 0.9948 - 9s/epoch - 24ms/step\n",
            "Epoch 93/100\n",
            "354/354 - 9s - loss: 0.0583 - accuracy: 0.9931 - 9s/epoch - 24ms/step\n",
            "Epoch 94/100\n",
            "354/354 - 9s - loss: 0.2093 - accuracy: 0.9444 - 9s/epoch - 25ms/step\n",
            "Epoch 95/100\n",
            "354/354 - 9s - loss: 0.4521 - accuracy: 0.8817 - 9s/epoch - 25ms/step\n",
            "Epoch 96/100\n",
            "354/354 - 9s - loss: 0.3489 - accuracy: 0.9101 - 9s/epoch - 24ms/step\n",
            "Epoch 97/100\n",
            "354/354 - 9s - loss: 0.1688 - accuracy: 0.9574 - 9s/epoch - 24ms/step\n",
            "Epoch 98/100\n",
            "354/354 - 9s - loss: 0.1100 - accuracy: 0.9769 - 9s/epoch - 24ms/step\n",
            "Epoch 99/100\n",
            "354/354 - 9s - loss: 0.0903 - accuracy: 0.9845 - 9s/epoch - 24ms/step\n",
            "Epoch 100/100\n",
            "354/354 - 9s - loss: 0.0642 - accuracy: 0.9915 - 9s/epoch - 25ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0059921110>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('mobydic_model.h5')\n",
        "num_gen_words = 80\n",
        "n = np.random.randint(0, len(text_sequences))\n",
        "generate_text(model, tokenizer, seq_len, ' '.join(text_sequences[n]), num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "XQ5b-ETcfPSb",
        "outputId": "52778621-432c-4d91-d548-939dffacb09e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'leave me to dress afterwards leaving the whole apartment to myself thinks i queequeg under the circumstances this is a very civilized overture but the truth is these savages have an innate sense of delicacy say what you will it is marvellous how essentially polite they are i pay this particular compliment to queequeg because he treated me with so much civility and consideration while i was guilty of great rudeness staring at him from the bed and watching all'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_gen_words = 80\n",
        "\n",
        "test_text = 'Here I thought, every thing wa finished'\n",
        "\n",
        "generate_text(model, tokenizer, seq_len, test_text, num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "arNKXwzjjC83",
        "outputId": "4ec7d614-e6b2-450f-d23b-df23cfd368d2"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"the bowsprit reg'lar about the bag apartment it down as the bag and then smoking such two however and were there too ai no green stage trials on its sighs did so good fire and got a cannibal off from a bed like a bit and man stuck over to that sail of a cataract of how seem but cunningly somewhere ashore to be broad idea of sleeping from it sabbee of it were checkered with his old persians going\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_gen_words = 80\n",
        "\n",
        "test_text = 'I am very happy about'\n",
        "\n",
        "generate_text(model, tokenizer, seq_len, test_text, num_gen_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "4ota67dMjWU3",
        "outputId": "733bf676-7532-4ee5-aa65-bb00bc7544a5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"together arrived at a hamper ' tell 's all the great stove and the bench vigorously before a difference too not had not not to have unite come to please into a room sleeping upon great monkey jackets of scalding before the whaling into my creatures of icicles abominable followed the horse collar and at the quilt his wrist in me with his bed is when it must have go into the room or taking care of sailors no adjoining\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}